{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5663374",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43bbaaf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1cb466d2e90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For reproducibility\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291a5de2",
   "metadata": {},
   "source": [
    "# Lab07-1. Tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "480a955a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[1, 2, 1],\n",
    "                             [1, 3, 2],\n",
    "                             [1, 3, 4],\n",
    "                             [1, 5, 5],\n",
    "                             [1, 7, 5],\n",
    "                             [1, 2, 5],\n",
    "                             [1, 6, 6],\n",
    "                             [1, 7, 7]\n",
    "                            ]) # (m,3)\n",
    "y_train = torch.LongTensor([2, 2, 2, 1, 1, 1, 0, 0]) # (m,)\n",
    "\n",
    "x_test = torch.FloatTensor([[2, 1, 1], [3, 1, 2], [3, 3, 4]]) # (m',3)\n",
    "y_test = torch.LongTensor([2, 2, 2]) # (m',)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89e03f2",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e0e85bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxClassifierModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(3,3)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df357d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SoftmaxClassifierModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48ebd3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4468cad",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47b5af65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, x_train, y_train):\n",
    "    nb_epochs = 20\n",
    "    for epoch in range(nb_epochs):\n",
    "        # H(x)\n",
    "        prediction = model(x_train) # prediction = (m,3)\n",
    "        \n",
    "        # cost\n",
    "        cost = F.cross_entropy(prediction, y_train) # classification\n",
    "        \n",
    "        # H(x) 개선\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print('epoch {:4d}/{} Cost: {:.6f}'.format(epoch, nb_epochs, cost.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60172fd",
   "metadata": {},
   "source": [
    "## Test(Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36a37dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, optimizer, x_test, y_test):\n",
    "    prediction = model(x_test) # (m',3)\n",
    "    predicted_classes = prediction.max(1)[1] # 각 행마다 가장 큰 값의 인덱스 가져오기\n",
    "    correct_count = (predicted_classes == y_test).sum().item()\n",
    "    cost = F.cross_entropy(prediction, y_test)\n",
    "    \n",
    "    print('Accuracy: {}% Cost: {:.6f}'.format(correct_count / len(y_test) * 100, cost.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5f809e",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4131cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    0/20 Cost: 1.142985\n",
      "epoch    1/20 Cost: 1.117769\n",
      "epoch    2/20 Cost: 1.100901\n",
      "epoch    3/20 Cost: 1.089523\n",
      "epoch    4/20 Cost: 1.079872\n",
      "epoch    5/20 Cost: 1.071320\n",
      "epoch    6/20 Cost: 1.063325\n",
      "epoch    7/20 Cost: 1.055720\n",
      "epoch    8/20 Cost: 1.048378\n",
      "epoch    9/20 Cost: 1.041245\n",
      "epoch   10/20 Cost: 1.034285\n",
      "epoch   11/20 Cost: 1.027478\n",
      "epoch   12/20 Cost: 1.020813\n",
      "epoch   13/20 Cost: 1.014279\n",
      "epoch   14/20 Cost: 1.007872\n",
      "epoch   15/20 Cost: 1.001586\n",
      "epoch   16/20 Cost: 0.995419\n",
      "epoch   17/20 Cost: 0.989365\n",
      "epoch   18/20 Cost: 0.983424\n",
      "epoch   19/20 Cost: 0.977591\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d4f248d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0% Cost: 1.346748\n"
     ]
    }
   ],
   "source": [
    "test(model, optimizer, x_test, y_test) # 이미 오버피팅된 상태"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7348f2",
   "metadata": {},
   "source": [
    "## Learning Rate\n",
    "- learning rate이 너무 크면 발산하면서 cost가 늘어난다(overshooting)\n",
    "- learning rate이 너무 작으면 cost가 줄어들지 않는다\n",
    "- 적절한 숫자로 시작해서 발산하면 작게, cost가 줄어들지 않으면 크게 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d57e857e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    0/20 Cost: 1.280268\n",
      "epoch    1/20 Cost: 976950.687500\n",
      "epoch    2/20 Cost: 1279135.125000\n",
      "epoch    3/20 Cost: 1198379.125000\n",
      "epoch    4/20 Cost: 1098825.625000\n",
      "epoch    5/20 Cost: 1968197.625000\n",
      "epoch    6/20 Cost: 284763.125000\n",
      "epoch    7/20 Cost: 1532260.125000\n",
      "epoch    8/20 Cost: 1651504.250000\n",
      "epoch    9/20 Cost: 521878.437500\n",
      "epoch   10/20 Cost: 1397263.125000\n",
      "epoch   11/20 Cost: 750986.250000\n",
      "epoch   12/20 Cost: 918691.750000\n",
      "epoch   13/20 Cost: 1487888.125000\n",
      "epoch   14/20 Cost: 1582260.125000\n",
      "epoch   15/20 Cost: 685818.000000\n",
      "epoch   16/20 Cost: 1140048.750000\n",
      "epoch   17/20 Cost: 940566.750000\n",
      "epoch   18/20 Cost: 931638.125000\n",
      "epoch   19/20 Cost: 1971322.625000\n"
     ]
    }
   ],
   "source": [
    "# 발산\n",
    "model = SoftmaxClassifierModel()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e5)\n",
    "train(model, optimizer, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12c97eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    0/20 Cost: 3.187324\n",
      "epoch    1/20 Cost: 3.187324\n",
      "epoch    2/20 Cost: 3.187324\n",
      "epoch    3/20 Cost: 3.187324\n",
      "epoch    4/20 Cost: 3.187324\n",
      "epoch    5/20 Cost: 3.187324\n",
      "epoch    6/20 Cost: 3.187324\n",
      "epoch    7/20 Cost: 3.187324\n",
      "epoch    8/20 Cost: 3.187324\n",
      "epoch    9/20 Cost: 3.187324\n",
      "epoch   10/20 Cost: 3.187324\n",
      "epoch   11/20 Cost: 3.187324\n",
      "epoch   12/20 Cost: 3.187324\n",
      "epoch   13/20 Cost: 3.187324\n",
      "epoch   14/20 Cost: 3.187324\n",
      "epoch   15/20 Cost: 3.187324\n",
      "epoch   16/20 Cost: 3.187324\n",
      "epoch   17/20 Cost: 3.187324\n",
      "epoch   18/20 Cost: 3.187324\n",
      "epoch   19/20 Cost: 3.187324\n"
     ]
    }
   ],
   "source": [
    "# 줄어들지 않는 cost\n",
    "model = SoftmaxClassifierModel()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-10)\n",
    "train(model, optimizer, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f4b9334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    0/20 Cost: 1.341574\n",
      "epoch    1/20 Cost: 1.198802\n",
      "epoch    2/20 Cost: 1.150877\n",
      "epoch    3/20 Cost: 1.131977\n",
      "epoch    4/20 Cost: 1.116242\n",
      "epoch    5/20 Cost: 1.102514\n",
      "epoch    6/20 Cost: 1.089676\n",
      "epoch    7/20 Cost: 1.077479\n",
      "epoch    8/20 Cost: 1.065775\n",
      "epoch    9/20 Cost: 1.054511\n",
      "epoch   10/20 Cost: 1.043655\n",
      "epoch   11/20 Cost: 1.033187\n",
      "epoch   12/20 Cost: 1.023091\n",
      "epoch   13/20 Cost: 1.013356\n",
      "epoch   14/20 Cost: 1.003968\n",
      "epoch   15/20 Cost: 0.994917\n",
      "epoch   16/20 Cost: 0.986189\n",
      "epoch   17/20 Cost: 0.977775\n",
      "epoch   18/20 Cost: 0.969660\n",
      "epoch   19/20 Cost: 0.961836\n"
     ]
    }
   ],
   "source": [
    "# 적당한 lr\n",
    "model = SoftmaxClassifierModel()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-1)\n",
    "train(model, optimizer, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d766914a",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1edbd6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[73,83,75],\n",
    "                            [93,88,93],\n",
    "                            [89, 91, 90],\n",
    "                            [96, 98, 100],\n",
    "                            [73, 66, 70]])\n",
    "y_train = torch.FloatTensor([[152],[185],[180],[196],[142]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee001f3",
   "metadata": {},
   "source": [
    "### Standardzation(정규분포)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e455e329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([84.8000, 85.2000, 85.6000])\n"
     ]
    }
   ],
   "source": [
    "mu = x_train.mean(dim=0) # 세로 기준\n",
    "print(mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d0df6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11.0544, 12.0291, 12.6214])\n"
     ]
    }
   ],
   "source": [
    "sigma = x_train.std(dim=0)\n",
    "print(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2bdb0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_x_train = (x_train - mu) / sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ecd18b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0674, -0.1829, -0.8398],\n",
      "        [ 0.7418,  0.2328,  0.5863],\n",
      "        [ 0.3799,  0.4822,  0.3486],\n",
      "        [ 1.0132,  1.0641,  1.1409],\n",
      "        [-1.0674, -1.5961, -1.2360]])\n"
     ]
    }
   ],
   "source": [
    "print(norm_x_train) # 정규분포를 따르는 data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "860ef8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultivariateLinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(3,1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0ebf2d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultivariateLinearRegressionModel()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 1e-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7ea42b",
   "metadata": {},
   "source": [
    "## Training with Preprocessed Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "05b28078",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, x_train, y_train):\n",
    "    nb_epochs = 20\n",
    "    for epoch in range(nb_epochs):\n",
    "        \n",
    "        # H(x)\n",
    "        prediction = model(x_train) # (m,1)\n",
    "        \n",
    "        # cost\n",
    "        cost = F.mse_loss(prediction, y_train)\n",
    "        \n",
    "        # H(x) 개선\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print('epoch {:4d}/{} Cost: {:.6f}'.format(epoch, nb_epochs, cost.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a08b8cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    0/20 Cost: 29476.503906\n",
      "epoch    1/20 Cost: 18732.742188\n",
      "epoch    2/20 Cost: 11949.518555\n",
      "epoch    3/20 Cost: 7636.165039\n",
      "epoch    4/20 Cost: 4883.999023\n",
      "epoch    5/20 Cost: 3125.119873\n",
      "epoch    6/20 Cost: 2000.174561\n",
      "epoch    7/20 Cost: 1280.415649\n",
      "epoch    8/20 Cost: 819.816589\n",
      "epoch    9/20 Cost: 525.033325\n",
      "epoch   10/20 Cost: 336.358704\n",
      "epoch   11/20 Cost: 215.590012\n",
      "epoch   12/20 Cost: 138.281021\n",
      "epoch   13/20 Cost: 88.787140\n",
      "epoch   14/20 Cost: 57.095325\n",
      "epoch   15/20 Cost: 36.797890\n",
      "epoch   16/20 Cost: 23.793510\n",
      "epoch   17/20 Cost: 15.457666\n",
      "epoch   18/20 Cost: 10.110308\n",
      "epoch   19/20 Cost: 6.676270\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, norm_x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa17045f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ec2d16",
   "metadata": {},
   "source": [
    "# Lab07-2 MNIST Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8522dbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9e0c0eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST\\raw\\train-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "102.8%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST\\raw\\train-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST\\raw\\t10k-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "112.7%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\user\\anaconda3\\envs\\PyTorch\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "# data download\n",
    "mnist_train = dsets.MNIST(root=\"MNIST_data/\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "mnist_test = dsets.MNIST(root=\"MNIST_data/\", train=False, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e1a24d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset loader\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a703331",
   "metadata": {},
   "source": [
    "### setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "35c86009",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# for reproducibility\n",
    "random.seed(777)\n",
    "torch.manual_seed(777)\n",
    "\n",
    "# parameters\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "# MNIST data image of shape 28 * 28 = 784\n",
    "linear = torch.nn.Linear(784, 10, bias=True).to(device)\n",
    "\n",
    "# cost/loss & optinizer\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device) # softmax is internally computed\n",
    "optimizer= torch.optim.SGD(linear.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a6476b",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ae47c3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 0.535150588\n",
      "Epoch: 0002 cost = 0.359577745\n",
      "Epoch: 0003 cost = 0.331264287\n",
      "Epoch: 0004 cost = 0.316404700\n",
      "Epoch: 0005 cost = 0.307106972\n",
      "Epoch: 0006 cost = 0.300456554\n",
      "Epoch: 0007 cost = 0.294933408\n",
      "Epoch: 0008 cost = 0.290956199\n",
      "Epoch: 0009 cost = 0.287074089\n",
      "Epoch: 0010 cost = 0.284515619\n",
      "Epoch: 0011 cost = 0.281914055\n",
      "Epoch: 0012 cost = 0.279526860\n",
      "Epoch: 0013 cost = 0.277636588\n",
      "Epoch: 0014 cost = 0.275874794\n",
      "Epoch: 0015 cost = 0.274422705\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = len(data_loader)\n",
    "    \n",
    "    for X,Y in data_loader:\n",
    "        # reshape input data\n",
    "        # label is not one-hot encoded\n",
    "        X = X.view(-1, 28*28).to(device)\n",
    "        Y = Y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = linear(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward() # 100개 데이터에 대한 평균 loss\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_cost = avg_cost + cost/total_batch\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('finished')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d034aa7",
   "metadata": {},
   "source": [
    "### Test & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "810e78b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.83%\n",
      "Label:  2\n",
      "Prediction:  8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test the model using test sets\n",
    "with torch.no_grad():\n",
    "    X_test = mnist_test.test_data.view(-1, 28*28).float().to(device)\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "    \n",
    "    prediction = linear(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    \n",
    "    p_sum = correct_prediction.float().sum() # 1의 개수, 맞게 예측한 개수\n",
    "    p_num = len(Y_test) # 전체 데이터의 크기\n",
    "    accuracy = 100 * p_sum / p_num\n",
    "    #accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy: {:.2f}%'.format(accuracy.item()))\n",
    "    \n",
    "    # Get one and predict\n",
    "    r = random.randint(0, len(mnist_test) - 1)\n",
    "    X_single_data = mnist_test.test_data[r:r + 1].view(-1, 28 * 28).float().to(device)\n",
    "    Y_single_data = mnist_test.test_labels[r:r + 1].to(device)\n",
    "\n",
    "    print('Label: ', Y_single_data.item())\n",
    "    single_prediction = linear(X_single_data)\n",
    "    print('Prediction: ', torch.argmax(single_prediction, 1).item())\n",
    "\n",
    "    plt.imshow(mnist_test.test_data[r:r + 1].view(28, 28), cmap='Greys', interpolation='nearest')\n",
    "    plt.show()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
