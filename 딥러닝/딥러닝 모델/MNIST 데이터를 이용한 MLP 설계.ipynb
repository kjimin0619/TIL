{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 1, Module Import '''\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt # 시각화 외부 모듈\n",
    "import torch\n",
    "import torch.nn as nn # 딥러닝 설계에 필요한 함수만 모아둔 파이토치 모듈\n",
    "import torch.nn.functional as F \n",
    "from torchvision import transforms, datasets # 컴퓨터 비전 연구 분야에서 자주 이용하는 torchvision 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version:  1.7.0+cu101 | Device :  cuda\n"
     ]
    }
   ],
   "source": [
    "''' 2. 딥러닝 모델 설계시 활용하는 장비 확인 '''\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "    \n",
    "print('Using PyTorch version: ', torch.__version__, '| Device : ', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n32개의 데이터로 1개의 Mini-Batch를 구성하고, 1개의 Mini-Batch로 학습을 1회 진행한다. \\n1개의 Mini-Batch를 이용해 학습하는 횟수를 'Iteration', 전체 데이터를 이용해 학습을 진행한 횟수를 'Epoch'이라 한다.\\n쉽게 말하면 'Epoch'은 존재하고 있는 Mini-batch를 전부 이용하는 횟수를 의미하는 것!\\n한 번의 Epoch을 위해 여러번의 iteration이 필요하다. \\n여기서는 전체 데이터 셋을 10번 반복해 학습하도록 설정했다.\\n\\n예를들어, 전체 데이터가 1만 개이고 1,000개의 데이터를 이용해 1개의 Mini-Batch를 구성한다면 1Epoch당 10회의 Iteration이 발생한다. \\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 32 # MLP 모델 학습에서 필요한 데이터의 단위. 전체 데이터에서 32개의 데이터를 추출하여 학습함\n",
    "EPOCHS = 10\n",
    "\n",
    "'''\n",
    "32개의 데이터로 1개의 Mini-Batch를 구성하고, 1개의 Mini-Batch로 학습을 1회 진행한다. \n",
    "1개의 Mini-Batch를 이용해 학습하는 횟수를 'Iteration', 전체 데이터를 이용해 학습을 진행한 횟수를 'Epoch'이라 한다.\n",
    "쉽게 말하면 'Epoch'은 존재하고 있는 Mini-batch를 전부 이용하는 횟수를 의미하는 것!\n",
    "한 번의 Epoch을 위해 여러번의 iteration이 필요하다. \n",
    "여기서는 전체 데이터 셋을 10번 반복해 학습하도록 설정했다.\n",
    "\n",
    "예를들어, 전체 데이터가 1만 개이고 1,000개의 데이터를 이용해 1개의 Mini-Batch를 구성한다면 1Epoch당 10회의 Iteration이 발생한다. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "043225a84a624c53bd112c0f764f605e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcbc685f84f0426baa7dd2b87f5da0cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c26b18c43bba470d94b459cabe1061db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd052f66366d4a398e91c81cd8a72b23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "''' 3. MNIST 데이터 다운로드 & Train/Test 셋 분리하기 '''\n",
    "\n",
    "# root : 데이터가 저장될 장소\n",
    "# train : 대상 데이터가 MLP 모델을 학습하기 위해 이용하는 학습용 데이터인지 판단. True = 학습용 데이터, False = 검증용 데이터\n",
    "# download : 인터넷상에서 다운로드하여 사용할 것인지 결정\n",
    "# transform : MNIST 데이터는 이미지 데이터이다. 데이터를 다운로드 할 때 ToTensor() 메서드를 이용하여 tensor 형태로 변경\n",
    "# 하고 0~255 범위의 스칼라 값으로 구성된 픽셀을 0~1 범위에서 정규화 과정 진행\n",
    "\n",
    "train_dataset = datasets.MNIST(root = \"../data/MNIST\", train = True, download = True, transform = transforms.ToTensor())\n",
    "test_dataset = datasets.MNIST(root = \"../data/MNIST\", train = False, transform = transforms.ToTensor())\n",
    "\n",
    "# DataLoader 함수를 이용해 배치 사이즈만큼 묶어 하나의 Mini-Batch 구성\n",
    "# dataset : 미니배치 단위로 할당하고자 하는 데이터셋 지정\n",
    "# batch_size : 미니배치 1개 단위를 구성하는 데이터의 개수\n",
    "# shuffle : 데이터의 순서를 섞거나(True) 섞지 않거나(False)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size = BATCH_SIZE, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset, batch_size = BATCH_SIZE, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: torch.Size([32, 1, 28, 28]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "''' 4. 데이터 확인하기 '''\n",
    "# 미니배치 단위로 할당한 데이터의 개수와 형태 확인\n",
    "for (X_train, y_train) in train_loader:\n",
    "    print('X_train:', X_train.size(), 'type:',X_train.type()) # (32,1,28,28)\n",
    "    # 가로 28개, 세로 28개의 픽셀로 구성된 이미지 32개가 모여있고, 채널이 1이므로 그레이스케일(흑백)로 이뤄진 이미지 데이터 셋\n",
    "    \n",
    "    print('y_train:',y_train.size(), 'type:', y_train.type()) # 레이블 값\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pltsize = 1\n",
    "plt.figure(figsize=(10 * pltsize, pltsize))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(X_train[i, :, :, :].numpy().reshape(28, 28), cmap = \"gray_r\")\n",
    "    plt.title('Class: ' + str(y_train[i].item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 5. MLP 모델 설계하기'''\n",
    "class Net(nn.Module): # torch 모듈 내 딥러닝 관련 기본 함수를 포함하고 있는 클래스를 상속받는 Net 클래스 정의\n",
    "    def __init__(self): # Net 클래스의 인스턴스 생성시 지니게 되는 성질 정의\n",
    "        super(Net, self).__init__() # nn.Module 내에 있는 메서드를 상속받아 이용\n",
    "        # 첫 번째 Fully Connected Layer\n",
    "        # MNIST 데이터를 innput으로 받기 때문에 28 * 28 * 1(가로 픽셀 * 세로 픽셀 * 채널 수)크기의 노드 수를 설정. \n",
    "        self.fc1 = nn.Linear(28 * 28, 512)\n",
    "        # 두 번째 Fully Connected Layer\n",
    "        self.fc2 = nn.Linear(512,256)\n",
    "        # 세 번째 Fully Connected Layer\n",
    "        # 0부터 9까지 총 10가지 클래스를 표현하기 위한 Label 값은 원-핫 인코딩으로 표현됨\n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "        \n",
    "        self.dropout_prob = 0.5 # Dropout, 몇 퍼센트의 노드에 대해 가중값을 계산하지 않을 것인지 명시\n",
    "        self.batch_norm1 = nn.BatchNorm1d(512) # 배치 정규화. 첫 번째 Fully Connected Layer의 Output이 512 크기의 벡터 값\n",
    "        self.batch_norm2 = nn.BatchNorm1d(256) # 배치 정규화. 두 번째 Fully Connected Layer의 Output이 256 크기의 벡터 값\n",
    "        \n",
    "    def forward(self, x): # Forward Propagation 정의\n",
    "        x = x.view(-1, 28 * 28) # view 메서드를 이용하여 2차원 데이터(크기가 28 * 28인)를 1차원 데이터로 변환\n",
    "        x = self.fc1(x) # 첫 번째 Layer 통과\n",
    "        x = self.batch_norm1(x) # 배치 정규화\n",
    "        x = F.relu(x) # 활성화 함수 적용\n",
    "        x = F.dropout(x, training = self.training, p = self.dropout_prob) # dropout\n",
    "        x = self.fc2(x) # 두 번째 Layer 통과\n",
    "        x = self.batch_norm2(x) # 배치 정규화\n",
    "        x = F.relu(x) # 활성화 함수 적용\n",
    "        x = F.dropout(x, training = self.training, p = self.dropout_prob) # dropout\n",
    "        x = self.fc3(x) # 세 번째 Layer 통과\n",
    "        x = F.log_softmax(x, dim = 1) # 출력층 활성화 함수 적용. softmax 함수를 이용해 확률 값을 계산함.\n",
    "        # Loss 값에 대한 Gradient 값을 좀 더 원활하게 계산할 수 있도록 log_softmax적용\n",
    "        # 최종 계산된 x 값을 Output으로 반환\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
      "  (batch_norm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batch_norm2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "''' 6. Optimizer, Objective Function 설정하기'''\n",
    "import torch.nn.init as init # 딥러닝 모델에서 초깃값(Weight, bias 등)으로 설정되는 요소에 대한 모듈\n",
    "def weight_init(m) :\n",
    "    if isinstance(m, nn.Linear):\n",
    "        init.kaiming_uniform_(m.weight.data) # he_initialization을 이용한 파라미터 초기화\n",
    "        \n",
    "model = Net().to(DEVICE) # MLP 모델을 기존에 선정한 'DEVICE'에 할당\n",
    "model.apply(weight_init) # MLP 모델에 he_initialization 적용\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, momentum = 0.5) # 파라미터 업데이트 시 이용하는 optimizer는 SGD로 정의\n",
    "criterion = nn.CrossEntropyLoss() # 평가 기준은 CrossEntropyLoss() \n",
    "\n",
    "# Cross EntropyLoss() : 손실함수. 교차 엔트로피 오차\n",
    "# MLP 모델의 output 값과 계산될 Label 값은 Class를 표현하는 원-핫 인코딩 값\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 7. MLP 모델 학습 진행 & 학습 데이터에 대한 모델 성능을 확인하는 함수 정의 '''\n",
    "def train(model, train_loader, optimizer, log_interval):\n",
    "    model.train()\n",
    "    for batch_idx, (image, label) in enumerate(train_loader):\n",
    "        image = image.to(DEVICE) # Mini-Batch 내에 있는 이미지 데이터를 기존에 정의한 장비에 할당\n",
    "        label = label.to(DEVICE) # Mini-Batch 내에 있는 이미지 데이터의 레이블 데이터를 기존에 정의한 장비에 할당\n",
    "        optimizer.zero_grad() # optimizer의 Gradient 초기화\n",
    "        output = model(image) # 장비에 할당한 이미지 데이터를 MLP 모델의 input으로 활용해 output 계산\n",
    "        loss = criterion(output, label) # Loss 계산\n",
    "        loss.backward() # Loss 값을 계산한 결과를 바탕으로 Back Propagation을 통해 계산된 Gradeint 값을 각 파라미터에 할당\n",
    "        optimizer.step() # 각 파라미터에 할당된 Gradeint 값을 이용해 파라미터 값을 업데이트\n",
    "        \n",
    "        if batch_idx % log_interval == 0: # 학습 진행 과정 확인\n",
    "            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}\".format(\n",
    "            Epoch, batch_idx * len(image), len(train_loader.dataset), 100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 8. 검증 데이터에 대한 모델의 성능을 확인'''\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval() # 학습 과정이 완료된 MLP 모델을 평가 상태로 지정\n",
    "    test_loss = 0 \n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad(): # Gradient 흐름 억제\n",
    "        for image, label in test_loader: # 기존에 정의한 test_loader 내의 데이터에 접근\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)\n",
    "            # output과 레이블 데이터의 교차 엔트로피 오차를 구하여 loss를 계산하고 그 결괏값을 test_loss에 더함\n",
    "            test_loss += criterion(output, label).item()\n",
    "            \n",
    "            # 계산된 벡터 값 내 가장 큰 값인 위치에 대해 해당 위치에 대응하는 클래스로 예측했다고 판단\n",
    "            prediction = output.max(1, keepdim = True)[1]\n",
    "            \n",
    "            # MLP 모델이 예측한 값과 실제 레이블이 의미하는 클레스가 맞으면 correct에 더함\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
    "            \n",
    "    # (현재까지 계산된 test_loss) / (test_loader의 전체 데이터 갯수)        \n",
    "    test_loss /= len(test_loader.dataset) # 평균 loss 계산\n",
    "    \n",
    "    # 정확도 계산\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    \n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tTrain Loss: 2.830961\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tTrain Loss: 1.205610\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tTrain Loss: 0.803917\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tTrain Loss: 0.547920\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tTrain Loss: 0.489910\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tTrain Loss: 0.406093\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tTrain Loss: 0.520119\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tTrain Loss: 0.426548\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tTrain Loss: 0.551491\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tTrain Loss: 0.241219\n",
      "\n",
      "[EPOCH : 1], \tTest Loss: 0.0069, \tTes Accuracy: 93.46 %\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tTrain Loss: 0.464202\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tTrain Loss: 0.260982\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tTrain Loss: 0.255910\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tTrain Loss: 0.213979\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tTrain Loss: 0.376849\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tTrain Loss: 0.253737\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tTrain Loss: 0.193884\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tTrain Loss: 0.635570\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tTrain Loss: 0.227084\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tTrain Loss: 0.206222\n",
      "\n",
      "[EPOCH : 2], \tTest Loss: 0.0054, \tTes Accuracy: 94.74 %\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tTrain Loss: 0.454296\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tTrain Loss: 0.208044\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tTrain Loss: 0.182244\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tTrain Loss: 0.441328\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tTrain Loss: 0.221989\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tTrain Loss: 0.252474\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tTrain Loss: 0.128297\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tTrain Loss: 0.508763\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tTrain Loss: 0.154394\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tTrain Loss: 0.219280\n",
      "\n",
      "[EPOCH : 3], \tTest Loss: 0.0046, \tTes Accuracy: 95.45 %\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tTrain Loss: 0.362429\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tTrain Loss: 0.097343\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tTrain Loss: 0.422252\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tTrain Loss: 0.262993\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tTrain Loss: 0.133349\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tTrain Loss: 0.437468\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tTrain Loss: 0.461117\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tTrain Loss: 0.177616\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tTrain Loss: 0.299786\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tTrain Loss: 0.440961\n",
      "\n",
      "[EPOCH : 4], \tTest Loss: 0.0041, \tTes Accuracy: 95.91 %\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tTrain Loss: 0.319665\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tTrain Loss: 0.124529\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tTrain Loss: 0.168074\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tTrain Loss: 0.059570\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tTrain Loss: 0.211456\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tTrain Loss: 0.511188\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tTrain Loss: 0.152712\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tTrain Loss: 0.136038\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tTrain Loss: 0.601660\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tTrain Loss: 0.376187\n",
      "\n",
      "[EPOCH : 5], \tTest Loss: 0.0037, \tTes Accuracy: 96.24 %\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tTrain Loss: 0.121377\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tTrain Loss: 0.173916\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tTrain Loss: 0.233939\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tTrain Loss: 0.250129\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tTrain Loss: 0.504844\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tTrain Loss: 0.279955\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tTrain Loss: 0.359404\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tTrain Loss: 0.086562\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tTrain Loss: 0.176690\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tTrain Loss: 0.126562\n",
      "\n",
      "[EPOCH : 6], \tTest Loss: 0.0034, \tTes Accuracy: 96.62 %\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tTrain Loss: 0.448619\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tTrain Loss: 0.168733\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tTrain Loss: 0.431351\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tTrain Loss: 0.107607\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tTrain Loss: 0.478985\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tTrain Loss: 0.525765\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tTrain Loss: 0.045962\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tTrain Loss: 0.110669\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tTrain Loss: 0.105680\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tTrain Loss: 0.089725\n",
      "\n",
      "[EPOCH : 7], \tTest Loss: 0.0032, \tTes Accuracy: 96.83 %\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tTrain Loss: 0.119074\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tTrain Loss: 0.196810\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tTrain Loss: 0.256845\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tTrain Loss: 0.074205\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tTrain Loss: 0.179383\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tTrain Loss: 0.098624\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tTrain Loss: 0.216034\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tTrain Loss: 0.157103\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tTrain Loss: 0.210466\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tTrain Loss: 0.019264\n",
      "\n",
      "[EPOCH : 8], \tTest Loss: 0.0030, \tTes Accuracy: 97.03 %\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tTrain Loss: 0.422427\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tTrain Loss: 0.175602\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tTrain Loss: 0.170845\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tTrain Loss: 0.456180\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tTrain Loss: 0.198113\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tTrain Loss: 0.308970\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tTrain Loss: 0.168899\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tTrain Loss: 0.121028\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tTrain Loss: 0.101920\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tTrain Loss: 0.103200\n",
      "\n",
      "[EPOCH : 9], \tTest Loss: 0.0029, \tTes Accuracy: 97.07 %\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tTrain Loss: 0.339550\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tTrain Loss: 0.029634\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tTrain Loss: 0.047808\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tTrain Loss: 0.066913\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tTrain Loss: 0.171965\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tTrain Loss: 0.339445\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tTrain Loss: 0.236672\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tTrain Loss: 0.308936\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tTrain Loss: 0.249229\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tTrain Loss: 0.444679\n",
      "\n",
      "[EPOCH : 10], \tTest Loss: 0.0028, \tTes Accuracy: 97.20 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "''' 9. MLP 학습을 실행하면서 Train, Test set의 Loss 및 Test set Accuracy 확인 '''\n",
    "for Epoch in range(1, EPOCHS + 1):\n",
    "    train(model, train_loader, optimizer, log_interval = 200) # 진행상황 확인하는 주기는 200\n",
    "    test_loss, test_accuracy = evaluate(model,test_loader)\n",
    "    print(\"\\n[EPOCH : {}], \\tTest Loss: {:.4f}, \\tTes Accuracy: {:.2f} %\\n\".format(Epoch, test_loss, test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
