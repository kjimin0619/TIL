{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. CNN 모델 설계 순서\n",
    "\n",
    ">1. 모듈 임포트  \n",
    "2. 장비 확인  \n",
    "3. 데이터 다운로드  \n",
    "4. 데이터 확인  \n",
    "5. MLP 설계  \n",
    "6. Optimizer, Objective Function 설정    \n",
    "7. 학습 데이터에 대한 모델 성능 확인하는 함수 정의  \n",
    "8. 검증 데이터에 대한 모델의 성능을 확인하는 함수 정의  \n",
    "9. 모델 학습 및 성능 확인  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 모듈 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 장비 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Pytorch version: 1.7.0+cu101 Device :  cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else :\n",
    "    DEVICE = torch.device('cpu')\n",
    "    \n",
    "print('Using Pytorch version:', torch.__version__, 'Device : ', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32 \n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. CIFAR10 데이터 다운로드(Train/Test 분리)\n",
    "\n",
    "- CIFAR_10 데이터 셋은 **컬러 이미지 데이터**이다. 데이터를 다운로드할 때 이미지 데이터에 대한 **기본적인 전처리**를 동시에 진행한다.  \n",
    "- ToTensor() 메서드를 이용해 **텐서 형태로 데이터를 변경**하고, **픽셀을 0과 1 사이의 값으로 정규화**한다.\n",
    "- 모델이 정보의 순서를 암기해 학습을 진행하는 것을 방지하고자 **shuffle = True**로 설정한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation\n",
    "\n",
    "- 복잡한 모델을 만들기 위해서는 다량의 데이터가 필요하다.\n",
    "- 갖고 있는 **한정적인 데이터를 임의로 변형해 데이터의 수를 늘려 다양한 Feature를 뽑는 것**을 **Data Augmentation**이라 한다.\n",
    "- Data Augmentation을 사용하면 성능이 소폭 상승한다.\n",
    "- 학습 데이터에 이용하는 전처리 과정은 검증 데이터에도 동일하게 적용돼야 한다. \n",
    "\n",
    ">- transforms.Compose() : 이미지 데이터에 전처리 및 Augmentation으 다양하게 적용\n",
    ">- RandomHorizontalFlip() : 해당 이미지를 50% 확률로 좌우 반전\n",
    ">- ToTensor() : 0과 1사이의 값으로 정규화하고 텐서 형태로 이미지 변환\n",
    ">- Normalize() : 텐서 형태로 전환된 이미지에 대해 또 다른 정규화 진행. r,g,b 순서로 평균 0.5, 표준편차 0.5씩 적용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets.CIFAR10(root = '../data/CIFAR_10',\n",
    "                                train = True,\n",
    "                                download = True,\n",
    "                                transform = transforms.Compose([\n",
    "                                    transforms.RandomHorizontalFlip(),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
    "                                )\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root = '../data/CIFAR_10',\n",
    "                                train = False,\n",
    "                                transform = transforms.Compose([\n",
    "                                    transforms.RandomHorizontalFlip(),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
    "                                )\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                          batch_size = BATCH_SIZE,\n",
    "                                          shuffle = False)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                          batch_size = BATCH_SIZE,\n",
    "                                          shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 데이터 확인\n",
    "\n",
    "- 훈련용 데이터 50,000개, 테스트용 데이터 10,000개\n",
    "- 훈련용 데이터의 미니배치 개수는 1563, 테스트용 데이터의 미니배치 개수는 313\n",
    "- **하나의 미니배치(X_train)**에는 **32개의 이미지 데이터**가 존재\n",
    "- **하나의 이미지 데이터**는 **가로 32개, 세로 32개의 픽셀**로 이뤄져있고 **채널은 3(RGB)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset :  50000\n",
      "test_dataset :  10000\n",
      "train_loader :  1563\n",
      "test_loader :  313\n"
     ]
    }
   ],
   "source": [
    "print(\"train_dataset : \", len(train_loader.dataset))\n",
    "print(\"test_dataset : \", len(test_loader.dataset))\n",
    "\n",
    "print(\"train_loader : \", len(train_loader)) # 미니배치 개수 = iteration 횟수\n",
    "print(\"test_loader : \", len(test_loader)) # 미니배치 개수 = iteration 횟수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: torch.Size([32, 3, 32, 32]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "for(X_train, y_train) in train_loader:\n",
    "    # Mini-batch 1개 안의 데이터 확인\n",
    "    print('X_train:', X_train.size(), 'type:',X_train.type())\n",
    "    print('y_train:', y_train.size(), 'type:',y_train.type())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAABeCAYAAAAHQJEfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzsnX14HNV97z8zHq/Xy3q9XpZlEUIIIYxijOM4jus4ruO4DpdQQikhlEsoSZOUpim3t03TNE3TNG1TnjShaW4bEpKGEN7yHsJbCK/GccAYY4wxthBCCFmWZXm9Xq3X6/V4PZ69f/zO7JkVK2tlGYOc+T6Pnj27OjNzzsyZc37n+3szKpUKAQIECBAgQIAAAY4O5hvdgAABAgQIECBAgMmMQJgKECBAgAABAgSYAAJhKkCAAAECBAgQYAIIhKkAAQIECBAgQIAJIBCmAgQIECBAgAABJoBAmAoQIECAAAECBJgA3jTClGEYXzQM4443uh2vJ070Pp7o/YOgjycKTvQ+nuj9g6CPJwJOpP4dV2HKMIyrDMPYYBhG0TCMnYZh/MowjKXHsw2NwjCMKYZhfMkwjEHDMPYZhvGcYRjxBo6bTH18v2EYW1Rb1xqGMaeBY07o/qnjJk0fPRiG8WHDMCqGYXy8wfqTpo+GYXzHMIyXDMNwDcP4yDiOO6H7OFn6ZxjGbMMw7jEMY7dhGDnDMB4yDOPcBo+dLH38XdVG/1/FMIwPNHDspOgjgGEYKwzD2GgYRsEwjF7DMK5t4JhJ0T/DMJKGYTxpGMYewzDyhmE8ZRjGuxo9/rgJU4ZhfAr4OnA9cCrQAnwT+IPj1YZx4p+BJcA7gRjwx4B9pAMmUx8NwzgHuBP4BBAH7gPuNQzDOsIxJ3T/1HGTpo8eDMOYBfw9sLXB+pOtj88DnwQ2NnrAid7HSda/OHAvcC7S1vXAPWMdNJn6WKlUflOpVKLeH3AxUAQePNJxk6mPhmFMBX4BfBuYCfwR8DXDMN56hGMmTf+Q5/VR4BRgFvDvwH1jrRlVVCqV1/0PufFF4INHqPNF4A7f958CQ8BeYA1wnu9/FwGdwD5gB/Bp9XsSuB/IAzngN4B5FO2dpdp79gncx+uAX/q+m8AB4Pd+G/s3Gfvou85NyEK8Gvj4iTROR7TrCeAjJ9q7ON4+Tub+qfMmgApw8gncx1uAW06k54gIQxUg4vvtGeB/nwj9G9EuE3i/6m+qkWOOFzP1TiCMSLWN4lfAOUAK2a3d6fvfzcCfVSqVGcBcYJX6/W+AAUSyPBX4HHIzXgPDMO43DOOzo1z7fMABLjcMY8gwjG7DMP5ijPZOtj4a6m/k97mj1D/R+weTr48YhrEIWIgIVI1g0vXxKHCi93Gy928ZMFSpVPYcoc6k7aNhGBHgcuDWMapOqj5WKpVdwA+BPzHEDOadwJnIBqAeJlX/fHU2I1qoe4HvViqVTCMNb4y+mjhOBrKVSsVp9IBKpfI9r2wYxheBYcMwZlYqlb3AIWCOYRjPVyqVYWBYVT0EnAacWalUehAJdbTzX3yEyzcjUvVs4Czk4T5mGEZ3pVJ5ZJRjJlsfHwG+bBjGcmAt8HdACIiMUv9E7x9Msj4ahjEFocz/T6VScQ3DGK2qH5Oqj0eJE72Pk7Z/hmE0AzcCnxqj6qTtI/ABIAv8eox6k7GPPwS+C/w/9f3PK5XK9lHqTsb+UalU5hmGEQb+EFkzGsLxYqb2AMlGdY9K6v2yYRivGIZRAPrUv5Lq8wMI5bfNMIxfKwkZ4KtAD/CwMo472p3gAfX5L5VK5UClUtkM/EhdczRMqj5WKpUu4MPAN4Cd6rqdiIRfDyd6/2CS9RFR7W2uVCpPjeOYydbHo8GJ3sdJ2T/DME4BHga+WalUfjhG9UnZR4UPA7dVlL7oCJhUfTQMowP4MXANImScB3zGMIzfH+WQSdU/PyqViq3G6GeNI9iEjTzodf9D604vP0KdL6J0p4ix94sIK2QgBowVoH3EMVOBvwa21znfeUCGI9jIHKEtZ6vrtfh++2/gP0+UPtY5VxzRRXf8NvZvMvYRuBvZnQ2pvzJia/CNE6WPI84zXpupE7KPk7F/iB3qc8CXG6w/6fqoznEGYiIypr3tZOsjorp8bsRvX2eU+Way9W+U9vUAf9hI3ePCTFWEovsCcKNhGJcahhExDGOqYRjvMwzjK3UOmQEcRCTbCOIJAIBhGCHDMD6kqL9DQAE4rP53sWEY7YZhGL7fDx9Fe19BqMJ/MAxjmmEYb0E8F+4/UfqozvV2tRs4BfHQuK8ijM5vXf8maR8/ArwFmK/+NiBeqP9wAvXRu04YmWCnGoYRNgxj1LnrRO/jZOufYRgx4CHgyUql0hBrMNn66MMfA2vVGnKi9fE54BxDwiMYhmGcjXgtPn8i9M8wjMWGYSxV15puGMbfITZYTzd0gmMhvY1DyvsQMuHvR3bSvwSW1JFQo4jr7D5gG0IrVoB2hF58ENmRFxBvgqXquL9GqMH9iDrnH4/Qll8BnzvC/09X1ykCvYjh24nWxyfU9XOIsHHSb3v/JlsfR9RdzRjefJOxj6pflRF/y3/b+zhZ+oeovSrqPEXfX8uR+jeZ+uir0wV8rJF3cDL2EbgC2KLaMICEDzii59xk6R/wbkQw9NaMXwPLGn2OhjpJgAABAgQIECBAgKPAmyadTIAAAQIECBAgwGREIEwFCBAgQIAAAQJMAIEwFSBAgAABAgQIMAEEwlSAAAECBAgQIMAEEAhTAQIECBAgQIAAE8DxSicDgGEYNa6DJ/nKru/zoO/3aerT/9sxbZP6bMSnsVKpjJmvo2nF5ZVIoR+AV559BqZMB+D85ZdhheR2z52/gLBpA/Cj736FfbskRdVJwNJ3SlDXJRcuY+GixVJ/7jwikRgAtl2kXLar5Xw+B8CVV17J9m1edP2jRwN9fF3dP3s3b+CJB+8FIDPYT/+ApEX6zJeup7mjQ9UK4ah9wFEM4DGf4chxOtnQyDhddM0dFcuSuxcyTSx1P13XJRSSDAqmaeLVMU2w1FtqWWb1fTVNs7ojc10Xy1LHOiGGMvIeOG6BdCIt18KimC8AEI8nCCWicqxp4phy1rJZplyScV3KDBCJqDZYJrZdBuCub3xqzD62GEYlrMoJYL13fxBfapB4BM+NdaIR+Nv3nCVtyw6wpesQAPMWzeSuJ/cCkoHVj/PUZyfje3nGeo6GYVQ4w/eD19k2xAEdOGMRUJJyuQAXqmQazbNnkkhJeyMpyBbl94EhULcY04LMoJQLIbASUo5bkMir85T/gKEuGQFbNvfS1Schh/bYiHM5SAjF/ar8HviDT0rx7svHHqcTehenMerCMeM0+UwnIJaWlajg7KcgQ5NdfTBVDexDR8ogWG0oEmIS5DmoBCqVzNh9jH5+fcVWc7oLVAq2+o/JtJA8VNOyOFBWD9KxoSgPYFYiSiQi703IjJJH1omQZVFSjXAcMMfgTVw0sxKyTCxkEJRKZUq+ZDD+h2GYas742tKx38XZLZWwI+dcungZbe0ylxfNCGZYzQGuW13P4rEo9pDMH4/efz/9214FJGbBscCZs06mpbUNgHRLM00tzQAk0k2EYhJwPRQOE41K26698tIx+xgwUwECBAgQIECAABPAcWWmRkJtgEhT3UhxaEQdT9jPo9mrkXU8TPX9z6CxXaB3A1wmFva2ilKJYqFU/Xru/EUADGUyFEuym2jvaCGsdtsXXXQxc2aLVLxo3mJaWubIacJlknHZZYRdMG3ZreQyQxRKcv5kIklb61wALlh5OTff/D/HogdjwnXdsSuN83yWYiU2rV3FHV/7EgClXIVIeiYAuYF+mtvbAXAwcU25f+NtiWkG+wcP3r2wTKuGXcJX9r6bpoljVg/Eu/MuVNkry7LI5WWMP/jwGiovPeCdCWhSZQuJuQdMT0NE0SnhiH6YTgF296ovGaacJWO8Y85sIpEj5amuxWjZV0EiK8L4WSmAbzwuu+QFM6BQnYxcxQnUMlNnAcvPmwVAa88wmw7qOlNUncNIRliAhdPhoQM0Dq+TpyJ57gEGkUkVKJuw6wn1+zbo4VRp7co24kslpWPRBkfd+9mtMKgYpYF+KKhyjw1NKkOaGYacmuIGBu6hd5OUX17j6/wZcPIK3cw9HlO2FNZvUT9ePo5+HgXedfF59A8Jtbb9Sc3av+1/z2TF8oUAFAsZXEtunBWCsBpfTrFMKSN0XTFToJiXOmYkjpUU9rUcLWGpe2JFTKKmHGuZ5rjmyJLtUClLfcNrCIDtcNDx1hIXlGaDssP0qNJUhGIMl6RtMyMWVthRtU2hpPDe6erLWztpqjnAcZya+cBrv4tLxV/f16/KOPp48SWX8cC9Mh909Q+SbGoBIJaIkM/L4IhGozhFGXCZQpY5cxcA8KlFy1n/xGoAsv19RMNyHzZuXk9UaWxa00386LHHpF0NtGfb8B62DSvK8bln6tY51ZjG7NmzAbj2ykvHPOcbKkx5KFDbEG9+moYWuKJU2epRhalDaNVhE/ByA9ce7VxHCzufw/R4cqC/S6bt2fMXs/SKCwGYu2QhkUhUHVCiZMsCdPfGbrKPdgJQsor86ge3AfCnl13O568Tbtx1XQYGhP58Ys0GohERN6PR5mPck9FxrAUSF4dSIQvAhrVraE6KPiHZGmZLr0yG3RvXM2/JUjnACmk1kxUIR0cDx3GqQpCLWzNJ+uFNqmUHXEsmZ8tFqwItk0xWnl1XVxc7H1+ljtxMVddBxFcuU131D2yEA97z83RUqLpaojj86k4Atr76CFoEqZeNonHkJ3Cs17In98E7RTYhHE2y/J1yrzJP7cfTDA0AxFMAfOLzV/P9b/43AA/s9PeQan1zPIKUH7sQyQ0gDDNlrSKZhl2+R5uJzQcgPdumTwk4gxugV7TpXHoZtKtjizmdFTxswbOeUGbC78gaQ7QJBryJ2S9FNsEeT2JNwtsukWJPP+x7VP3+xaPraqN48udb9ZeT4KzFItQuWNhBolXNm0BMTcXxaAhXCTWlTAGUCroQtXALauyXwxCTMZuY24KdkPoFs4irNoSO4+C4Pt3YGKi4+v2rEQRMR7+XoZAumyYHlJR7EkWmh6Uv/m1GCcenivf9wx35g4ajhK+S61ZFL8e10O/u6MeOhbamJlZeeBEA69auoadnMwDNTS3E4jLfR0MuqajMSbl8Ebcs17JtaGkRlVyxkMMui5C75IILSMRbAUgnW+lYItL7P/3rqNm0xoVdlYPseumFhusHK1GAAAECBAgQIMAE8IYyUx4rtHfE7zPVZxTIqnICzVIdCZ6d40hWyk+pv54oZDOkE7JTmHXqGXz8mo8AsGTlRQwqVd29j65lQO3mh/r62N3XrRrdCyeLmg+rALu2AfD9H93NFz4l+UEjkRLz5wtFjdtFn2Juvvu9O8BQ5vqV18tc/9jCYz0s06WzR+7B6tVPUNguI6JpOmTVTv3u277H/OUXANA6f1F1l+a6geruaOA4Lo7S7dimUzVQNU2zem9Dpn5GJmbV6L9o2/R1CoO6o6sbXl2nztqPfktDyFsLkobN44Kq+UkVYr76IV99bzc8kjs++jdY2RyzE0gd9VlqsWmXfP7lsovo2Sz6rjs+egHXfeKfAHjlMHQqVuNLV1/Lw+uFljlw34s15zmdGQDkJmJi6xl8O7DXMzpfiLaV2D6dl9s/CsDL/d38QVzmo0SoF6e4G4DOzeCq1ymdhJJo1sl3wzSPgTLh6R/pa6GtGuBs+ZgxB/Z5mloLnvNYrW7g2aPv4lFjP7z6mKj6tjjrmdt8GQDzF8wnGZMxHjNdikrHOVS0KQ4IAzK0+lUGlGqyOKhvc8fFL2G1yZwbn5vGbNVsbcRT1TWEUZhh0wSlwiMUAstbrsvVlTsZMUmp18zOZikovWMBfX0TcKtM2djtcl1XO4QdUZXX+Lx71w9uo3m2qOsTYYvebrmhuVyRucoUBqtMyZWOFW0XU81PluMSUeYAbW3NfOUr/w5AU2IKl19xHQCFUJKimnqmz5zGgb3Hfw18U6j5/JiFJvz9rPHOCZ53tCnYE7IsNE06crofD2KxCKWQ2IcMJ9KsGpBX7/tf/ga7uxWvvmMzeiA6yOIBcBCiqvfbtB730O4B7l8l6pMFCzqqA2vBkvksXCK0/ROb1vLLnyoRcjq1OoQ3LTyBqMz6dbIgP7Vdi9ZbD1B1Vtq4dSc/uOmbAHzii60km5UuIpCjjgplNwyO57Xns5/CwiyrideiaqNUKBYZyoqt08urHoU9G9SZcmgBykIbZER95TJ6m+PHyeilCfSqP3GvVA/nqs8VgBox/BeQnMA5/+h95wPQmYUXnhE1wL33rqKcU1u/VBt9vgnk8RdeASDjhMjY9abcM2g9VzZInd3d/FH7UYp6nlCTpCq7HtgAens6G/7Ze24mW26UZ7sotZsmZSUwlANTrAjIl8H21t4QzFM3cMM6YK0+ZfURngmniiUDxTB6ddmEePSBNo5tEOd9eCqZ1SJQ7942vmNHw9O/PszTv/4pAH//F2dz5aXLAUhFQkT7lW1UV5nuJ3oAyD+mm59HMvYCrLkHwspdMHn6Ni7/yukARJIxSuXG1XyY+OYx02feZPl+dzHUvF/BZGpIqSPLNnllFza0YSMdF18pv2NhqyY4jlsVkE3H1NpCaqdP7231qx1r/lGD0U0D6qGnr5OnntVq19Nl70DRdkimZbwnkwtw1aCxHcjmpF9WCEpFmXvuvu07HFTv1qu7D9O7RQbivCUJour+XHX5Ndx1208AGD40kqp5/RAsRQECBAgQIECAABPAm4aZ8hiiFmo3L7PU57Haq54C7PZ99zaQfvLT5OiZqWRyHi/3KWp291qeffFX4zvBtt/U+fEgX7n+iwAsW7GCiy+RYDGzZ7cQi4s03tIc0zGzXndWytt1+WXxEXK563244FHMpolZM+Q8TxKbkl2iHvzOSnff8mNA4nRd/Mnr1H/CWGrbZbpUR7RrglnPCNR80wz5NxR5N0bIlVEfdh2UgwxWKIz38DKFHL2bRHV14Nl1iBoPJGKS98ZYvrL/fpfQjNXIATnVawW1JrfH1ksUNBtVQpMpn6WWD/PwbuBypQvM7tQef1l0T8LAsieEjUrsg3bv/E+/WB3ZX3v59rrzx5buTq776F8BsKx1PX/xP99W/9nOky9p38OW/NY6RzeAeo+kE6h4u/Nn1B/A2byyrg+AOZdDizIoLwIl1ZHN/bBTxZmaYUJIEeiVXjCWSPniiyGiaL5METYqddj+H6GHwwAwT5XHyS5d+ZFFPJh7Ejg6ZspzSCqjec8UeiTfe+MrtG4S5nBu22nYeemkUzSJ5JT6D21uArVrgzeyt++AQpfwV6HlYcr1p7P6WPWEGJsDhEMQVTqSkAWeo5JTplJQDyYc5lBI5ry8XcZ2pU5s/nJ6FXu8x7SYGvJiuLkcVnOhgVV1PMHxs0smldG4laqTjwmuz//dbLyTzS0t7N6jH+AOT5u9bzemKVqJRDzO7DkLVRcjFBTTm0hEeeD+uwB4YUetJLBhnYznWNNsoklxYW1taeNzXxSPcMsyyeXluWSzg2QG5clvXreGl/fUXyg9Hjcxcybt7e1169TDm2ZlifvKtq88lhB1O+BZbNx4hHqKVaSEDgQaRYsAu33lJPrlGa+3X2t7By8/c7/6tmucR/txDpykZsT9W3n1FbGxKJXLdHaJfdFVV13GhRetBGDJgjmkP/ZWAO64+3lebiTQ3FHjtYue638RXXw2TS6ueqImVtUbxKwJI2eydPlyVf7XulfchVb//uSGf2H2Ipmd2xavxLSVXY9rVtvhWC7WKGYIAWBXLs8U5ZEXMR1MFVBvbyEPSm3A9rVokcJGixQOOhriFPSTcXx1juSg7IxSpziy4oShrDFoBr6vyr3AMlX+Z7R6fzYQU/YEZWC5+j2CnijLQEEtBC3U+ih6aAa+ocr+hXdg0xoWXSYboaZUnHOUMDXSvvPR3RwdPE1qEZncAJYgAhWMmEx7q1JTLH6YqLdmO6DiR9LWDN4eZ7gTCbkAkIa56gZ25eDl1er3QbSU0oseFmm0W+A40dISoatr7HrenJ5Aj6J91CqXvekgCcxV5SiQVVL2xi07qwFLLZ/GOowO7FGg/gZ/JpA2xf6vbNkUx7MveG4jtapyb7SZYKjRabpaQDYBFWTyUHszCbWhTidT1dAkphNit/L6ppgXlzigEolyKOrZKboQVg8pX6C6ApomFNVdtG3wwpHEExIXw8N4pIdwbNR/vfzKLvV5KyefLAGbk6lmigXpi2XCtu31A534Q7qUijJYh9wMSSXgxyIJEim5Vy1tc4krQTVqRRi45xcApGbMYN48WU/STc2E43Kw4zjE437J5MgIlpYAAQIECBAgQIAJ4LgyUzOoHw5+CnqH18drvfvq4b3qM47eZRwJ/nhVHmnjUquY8HYxJWr32gkaxyMPf4NaReJrMWX6LA4f8O9rVLCa81ZwivJ42N2bga5Vrzl21/ZXuPhi8UTJDOVQhAJuschPbpZUDhe95wwGwq0A/PxX9dSGE8Vrh43pt1d03WoUQMctU7JllxONRjFNTStXDzFDtLVJeoE//9jH+NbNN9e9qrfpLW/fzw/+ReIM/eV35pBQ9G7Z1MyTCdg+Bs3jwfzRjCaK0TxEx5Oi6A3Dr2/jsLJY3lfjbZelvrH4aDg8zvow+p05tr6270V77YUAlUmlSrCAMFdJXx1vd1mkGloU0OxV2FcuodkOP283D/iS7zze7/HVq8l6jFFzE1f8L5nFerJFtiivrUzvABd2pBvuY13sAN4ixbdeCEWlkntlk6/OI2lhjwDb3cmgZ1sRgYhiQFpjEJPwPmx2IafomQMFeME71yDaIjvv6+whNJ2TQsKOHQUS0RimPXY9jyf1OxL515pTfb9nfL+3A3k1HMt7tQ1/Hj1OkkiGHoAt1HeT2At0rpWVZe7ysyg7/tEzBk5qPYLBt2cv4YuseqgEWfW+pmO0tiuHpCaTUKuMna7+DA9tUfqV7ox4AwKQ1ZN1KKIDhBbytdSKx0yVStqLMJ4AU9V3HZ9tzBVjdjFvN2aQv2fPcM3nWIjGhJM0LYuyWgydYrkax7GltQ1HOQPk83nuv1fUhffc94vqObbt28e2J598zbmnTp3OoUOiCrz+a18esy3HVZhy0QtNmJqYrOOmyDzm+jM0tkB6L5uJ1qOPtgSkgVZVHodPhmDPKILUlHP5vYsl1145H+KJjWK1UdnXhfd6GqFWSraiQwd74GD9WaSlWV7tlRcsr3o/5PqyeJYW7uPbufL/ilCWyU/lN08d49Ckrk9iqf7m4jnUmoDtStsfePABcjmZvi697DJiMXkDLZ++zXFDOOopfvozn+OJVZJF7YVXawOmeUvwEHDvrx4HYM737uDSz4j9VBabiCP3I2qa9GRF/CoUC5QVf79i3gqOFUZb+o+9T9rrgUfe6Aa87uhBC0Q5asOseKKjL4QoFjpQg+n7vUxt7lCv7Ff/5NHqpTa0EGejbUCzjzzHxkck5nrz28+ke5PYkBSTp2ErI67sod0M9B8DdaeSCuJRUCnIWLQIcmr2e+iRNDwnd8cNoVXiFsRj+hyepihahqjaVb6URwtHYarR1kkgoQ9Gwm90Nu5+2ETGcWyG2vXAy4vYglZYl9DPtoR+5n5ZMIvWTLroLpYY3SFxlXqlOj7lEI6ERqlVB/sL6FFljij7vb59SmVH9aA/x9Oq/HRftuqhS6YEWVWn7OoQC1haKLNctPhoadtWF3A9vW8YDqn6dhkq3h0an31ja8dcXn3uxbErjhNDu2VlD4fCDKmcn81NzTgqoWDXps1kVILJe++/i+F9jXv3eYJUowjUfAECBAgQIECAABPAcWWmTN8F/WFISmj5eCTL5MUZWjEFHlZUgJ86H0AMPkGoXE92H83++gBwuq89HvXroHcrflM5/z6hcai8DlPmVKnQtyxspqdPJORtz/f4rlKutrriFijZ6g4UcozGizmub5+sqqTjzdV+xQFL7Z+uunIFra3C59/+w0YS7IwN7/qmq4O6uWVbO8qZJmvXS5S+a6/7BHt2CkezqWsL//IFUYDEYrHqeRzAVlRsuqmJm753EwDves+76l6/gqbgv/5P/0B4tuwbrXmtZPpkKx1xymwcENeE/sF+8sowc8U3Now83THFecBR+mIFOMZ4Fe3BZ6NtspNoAmU+Wo1fpla157FLeTQbEUNrN/x1TUaYBpyvPBajaZJbVL6xffvp8+o8u63KavXs2skrvnMNDje4Iz4DPXE6aPuId8DJrVJ0C2CrSS7RBPG4x8f34/Eta9dRnfwSaZitGmZnwKqaEUDB63BB18dFbiIIW+WpAGagXSYnEOpnoLuXzDj8eA6i5/RpaA1DE9pMoBv9DOf4jvWnGCqin/kQtbP1aE/H62axUMIJj2fVsKllo7x53+eeXLMS6aCdDGWhpHrcZ1G1fA/5bB6sMpTUgzwU0+c8WIapqo7raI9CB6jUiUBV8ZXHuSouWbKcx3/403Ed0wg8PdC3btF5aadOmV7Nkzh86HX1xKrBcVfz+b1i/L97E12I2nfvmnPks2MOdCgd/6Mv6JdkLZpqD6N120VgvSonqfWY8XTmh9B69Slotc0QtUPlqB22D28BV1qatR3y3ts6vYlq1thDvjtRylJJqCnZLDKaAtONylTgmFnMskz5VihcnUQSgF1QOe3Wb2Z2SqaMD3/gXG79+UtH2xsfVJtNi95eWZb6e3swlbvups4tfO0m8WfyBCmAG//j21xxlQSVmzung1BI+jcwmKWvrw+A5YsXs3CxqCjvvPnbfOhjf1a3Bd5ZnwU+ffXHALjgM39Mr/JEy2YHKJhyzmLpoJfz83XH4NhVTkCosNdYaLLbrzTbyBsVRdYz7SkBHarsolsWQ79l/gW0DESUj3TYhNSwPo/frqbp3WcCkO3bVuv2/4Ko1gtsJ3KuxFuYP28JsZ+KLqgHPYe1TIEn1OSzl9oca0fC26+AZGw6ACE3STQswlFTRw43rLy63EUM5iU8y0AG+r0OnrQH9ovb967PUw1dsGsxqBzsNEe1/VQ0oRvW2Qcve4+5V3UGtB4N5CaL+lgxAAAgAElEQVQdAxM4p1ga98jxZtTZaPVcGL3p3opeAxz0M8+jxZhean2xPY/xKGPDdlzKpfGoav3qPH/ZpVZ5ZOlPywulkACl0iJhQlStVhFfNupIyBcMuqjPM8VHb1hQE82z7rNzOVp9bTIU59y3CMnw0ouvHtU5GsWhwwcYPnz855tAzRcgQIAAAQIECDABHPc4U94u0O9J56Ipc790NxVYpyglNwIpZdm79EyYq/jZpQ4om2P6+vTvXd3QouyXLzgfPqnKu6kfO+owOvVEGW1MejTG8fq2DsBB6fHuQgfYal8TicCeIV13mtonh2LMbJb9097ZfdCjePIaS/kpVQcMx7Upl2WnYEVCVQZtCDAVFROzLAY6VZDB5Nn8zZ/9HgD3PryGl189GsP0Ao7nQmhC/4BsR6+/4cus2SAB1A4fgda//obrAVi+fAmxmPR7/bpOSsp7JJftY2iwD5DNVTWAzBFSLW1Tu6jVN92OtVB2P/12VjubuFMpFI6xEf4oeHMbnb8e+F30Pv9YsJ7HDiej30R/bs8YVUc2bgBUpksupdZgvbhXl705II82ZL/63FlkLOE+ctu2VVkLGz1/lIDISxK8KvvSTiIq4F1bCvqUbq+1Yyofz8v7+h87KsROmd5Q/y5f/n/I2MIMxyIxmlPCy5ejT7B5QE5ezD0oFgNA0amGGxIK/wX1jwO+Tq2CZ9XNsVZAU1TaUi67lIryEsbCcJ4K8rm1B/h1Q809KoSx8O7GaFzDO94Pz9ynv3vPvAX9HArUGk14U5TfXt5Fj+SR8UG972c10GbxKh6PPsOv2vNaMrLsZ6kcGFI0oNkCMcW/NUcl0CdwRkcHK+aKn2oqbhFSp7/+wU1UHlDHFn2qQ9OEg/7rjsaOHR3yg1kWLRS30tebmXqjcFyFqQh6yMTQA/cgOqhmBB3qoOlkaFkg5VQMkqq1ba3aaaE9BSHlI9i8eA4dKmli1w23EDlZ6rQuhEVKmPrlEdrn6dRT6BuTBsLT6tcfHd6MdYDq6zzQo7w2oFYZFMNoE7q9uT3FnFax4CiHW8jF5DzP/2Yzmnc9TFmFGnAck7Kie81IqMYDsay8N1paEkTVi9032IdbEiHuI5fNZ/U6mTUfebJxvfJP7rqNcFj4/lKxSK9Sz/UN9WshajpVqXlKx2kcfkpnVnzoh4/UfI7ET2/+cbU8ZRbMUrqZ4efHbtvLw8Aj+kUdr8N+PZyEtq84loKSFwO8CUidImU7By+83pm4jxn+l69cz4Xrjcd8at3bPUQQxSPIM/VG4jxfPRetveoBHvcdrywPWNrWQnGjuLWlqV1yPDXiAFqIc4FeZVeQ2gcLz5NZL791H3OUSvH3gSUrFjfUv1LBYTDTJ32aEyJnimFDX9821qgOWmal2pZkElrUe2mHYZff+MFbR0tU3dj6N0wn3rYUgFAoQlnNHWZ4CGwlXtQLJQ/HLMpFzE0yf4oIhk+NOOcH/l7CZ1562UIeTMpTvPMWLShl0c+wSH1zjX5q7aHGCrLeiBiQTMUpjyNvXW2maH9+S6gVavxQm/HWGH947ScAmNscxlERyqNWiCVzZJ62nDK2SrIYvmQe/5hTI/LhPnA9WyoHDDXTmTq4Mq4Dh/1+rR7GJ2QV8jnCoWMZmObNh0DNFyBAgAABAgQIMAEcV2bKb+Dnl3GnoOnYucB1//xOABKtCyg5wp60hgpke2SfYUUjNM8VnrlsWkRjottrJkn3evHWSofhDkW4WOtg0duk/OBzo2+awiM+QfYMuSOomOrDZ3w4ReTVd61sJR0X1ilkWmQG+gDIZ/tJpGRncslF7SxZJrtSK7KMIcX63H3XAh5eJUmvmtvjtLeJKjAcjlZDhrghiKvdrb1Xx42JWBZ5pbyY3ZFmKCt8fqZvE4vmyH0Lm3Dfbxpjp274xg3kBoRTTMVT3HTT9+Sabox//ft/li43zeSwI/vDhXPn8fRmT13ZwI08CWYqS9HmZkikheTPRg7w4lMNNfGYIoTeN85A7w9HY73OADoU7bTqkN71NgMh9fuWQ/Dp98uuev7ChdiuGAsPdHfypR/uP+L53xz4fXTPnuCYhCedcR7sO7Z+kP3odzmCfiv70IyFH+vRRuF+JqN/RD1PRfh/f/U8v6fKFyAGzyCMew0b5Sv71X/FrUJTJYGColOWAaUNa47YLw+r138LV5k+NEW1T0s+RzXQZSSm54KiDRfMlwDBve4un4H1TM6aL/lhUu0JEiFx6THLEdy8WiJCIWIqDlEm10fIUoGmQq8NdngskR0oYXlDzUcNn/9+uPASoa2jCZcrPvv7ANjhX/Lzb0mdpxs4fxhNrh1tFp8qFMOcTiXpGcocuW4NHOozUH5jGL8qMA5Ny6WYtChkZIT2hFM0JWVAPNA5wDfv7gMg072B5HyJr2eVTciqGc1y9KDxr3puCQ77jXD8LqN+/qVxpimb7WXN6gcarj8ZcVyFKb/VymiLhTUdFl50CQCJ9Eq6N60GoKvzAVra5IWPJpKEW8Q+oLl9Lpjy8ue7u1j/qNjkJIvas++2F+GOf/oAAJ8s/pz/HiVCgF/A8w+lcYRf45wz3sLKy68BYMP69SxaKCq8iy+6gPlzRIEZck0GlV1QoZTFVIkk06kU6bS8DKFogoij7IgynXz8Sun78ouXU3JKqm0WtgrY5oZMQsrbprQXHKXms8IWZly9AGGLQskLcjaNclHaMKcjTddAY8LUM6u3VdfO8qkDJBLiTbhhw5ZqncOvaKOpp7/3UF3p1QCaVCyHHTtgllLJLlgCg0rNEHUgrvS5zXNayA6ITc7u+mmaXhf4VXuNyNQXnAnKFAyrH7w0WImEDiTsPguFATlzqSXH7AUtUt/OsewUUWls2g2ectSnNcVGj8cJeJwfJTzlZAhYrco761cdiRkqyIlpwV5PWXISnn/U22JJzMR7AHh22xN4PZ4+PUpTXGxClq1cyS23f7Xh1kbR960DLciEqR86Zb2v7M/bOdIvyz+cvUAb/cBSVfZPqhZ6sc5Smx9uo6/sLb2tQMcrjenIZs+ZgRMRgWwgD8qBl7QJi5TtaDkEMSVw5UOwOberWr+KM5fQ1nyRlO0yPV1yIscuks9JxUQiSkgN5qFcmJItG8Op5XM59Drayq3rfoHf+F7Cv/g32RWvvLwDMyx3tlDIUCzK7H3lte9jzXfFe3H3Ecwk/VZpExaiPKgBM9A7SN4ez3bIH/bAodZOql4wzwhk1WS/o8Rj3SoASHuTBOgE6M/B8M9U/V20LhVhqnP9Bs5qkTn71XgTrOnVl/I8/mIhqskaQyFQOe/I5iCvVsnK+FR2t995+7jqT0YEar4AAQIECBAgQIAJ4Lh783mYhd41hqaApTZjkSQMDArLkUjPYfOmnwBww9ef4aorZVdy4YVzcbJydNG1iYaVQXbeZr5y5+tb8xQrVd6Y3v0wkBODvcs+/X66/0xcPx4a0SZ/mgjPVNxhfMzUtVdfyhUfFWYqd+UFpFR2bwdwlVGfFYrQnpJId66lH4LjONhe2P9SiYJyw7ngwqUkorKbyGX6cS0vFlUY1/Ry4LmUTd3mYk5uaNmxscLqulgMKlvhNVsP8pk/kd1NtjRIstHk2D6NTiwZp39QKOY1a1fXrz9ik/1nf/tBaeNQDzff/lz192FFFTx2XzVToVKvCP/SfvZerrrk/QB85/v3ceA46sEaybXn5embM0fi5YE4bXrMVDLpS4+Vg5xi33o6t+BaavcfN6vZzpvzsFPtrF10YEkTTbofV2bqpPeCLSwrh9czNiN1Ct6bM+WkGHPbWgFoa26mpMZ4OpUgqdILJaIREiqPyXXJa4ioMRsxHZqS8nsoFhoXM5VAM0dz0Uz1yD21x7cdpNanyh+3zTsmicQ2A1H7rlTldegMKwlqowZ5JFARzXL1oI3dB9HMVE+d9o2GZUuuoKT4tLWDL5BRpEEkBmV1ocEh2KzGWqQZyoqI2OnXQm3r4bHVKg/oUA52K4rLCFcH7XAqxdSUtPhQsQCKsSLSCjPUhfdp8+zTz5qGq/SL+f5DHBi3qYRg/gXv4PZviZfwmb8DF14j82bZHaJUljYUy6XqSxdNh1l6lRz7i1tHP+9y9TlShTsazpZQYbziG/bGWVDxW6QrvWmp4GKaU2gcI5MUeaPQH8xzRJTGqnrOgYKn381o36d8F/5IWXav8KB7n76XvU9Lpff949dZlZCJf246whIVrTURcYnHhJkKh8OUlWe4XSiwalMfAA/9x2qOPkfQiYnjKkwZ6MBpIfTEUj6sBRY3B3ZWBJ/uzQ+zVrnbd3RAKdsHwHe/8kVCEXmx2+YtZp5yuUxETZKzJfpcNBGnOPthAJbecpg1D4tu//LP/ZhrNssU233jzhrvDK8N/nxdo4fOrI9EKkVaLQqpZBjCKsCmC6YnTJkmjrI/cEqOjihuWdjqRbJMcFVI8XRrezVCeNkJVV8klzKWUhFSNimrhrroDphOmZhSlUXKFqm8rtP5qPDniy85nS6rXgrqI2Pr1j1c8xGZufbvbGxp//ZXx46CWy/g8fOvwPM33lfnP68/PCHKYHSBaoVakRMxSKtVsqVtFiVbRJ9y+SChkIhlHR0Vtiit6MbOg3zncVHtXfg22KLSV2kxU7xLvYU9hh6bfndvi/pJxI8KJ31IPtvmUZ3MB4dgv7cCx/F82qae0kJ7Ulr34ov3cdpJEsBz2YoVxBMiAqZSKSjLfWhKp0mlZWOQTERJJeTY7p5uWlUSueaODiyV29HODpIZEDFl3apV4+pGP1rgvA3J4wki7HgOuu3AwreJscutz+3WybTRQqs/l18Ine8tj54brn7rDHqelyfgzwnooNV8XkR11G/es8uj3f6HgW+r8k1j9M92B8gUJEtpb78E0wTIh+H51arSENVIkzOWQ2u9LMC8DC/UsX2onAYH1V3YPsihASXSR4qwvzp74xdBzzhf1LlXXPIJyuoOlgsF+vJiq+kMZXD6Gw9t27qgnX+/R+5yNGFRsuRYizKWuvuJRBOu8kqznQILl8kT+sWto9vg/arhFgDT4Lr/Ejvev/6gNtxMtYLKJ882n7tnT+dO5i8/cxwXCFMVTE6Kga3eucOj3CfDHxzXgWZZb2bOa2Vvb5/8PJit2cg+90sxJJv+jj8mFpP71pZOsmSekA9z0hFa1abFMh2ScRk0VsiiqNR8fUNZ7l3rz2o9HprhxEeg5gsQIECAAAECBJgAjiszNc+AAbW1346m18Po3XbHfmiKikEuoVZWLBPVXricYfX9OwDY9CTkldlg+aH76DhHGIvm5mnElEH0FR/9JC1tQlsmf3QzejPUxuKrvg7ABeuv49vPaPPDvSM+PTSa3gGgqaUdV1mCZwtFXJXQqlAoklEeHsVSkUJBpH3bdiiVpFwqFckqb7tsZhBb0atN7S00tbQC0NrUQVwZB5adYtVtx8KmqUmYj+5XKuTVdthxiphqa+qUCzSr3DvLdkBOBepzHZuWppPG0UuNV14en7LpFGVovvv4pUyaMLxxeqSwnwtVcLR0DJpT4laZtxJEHbn3A/3biadkZx9J2mzqFD3l2l3ayP3W52pO6TkHkea1EV5A+CHvd5OJMFNTYNrVUoy0wLDiVV64Cx2pycTLZHbWW+Ywb7aYW7clQyQVPZO4aAktTULLxZrSJBUDlc3m6OyUxC6XXbKUcETuiekUcZSqhrY0KTU445EQmUG5bn/3Fro2CcM82KudHBqB33D8IPATVb4GnYJqxdum0ZxW6kt2VxmlKJqNiqLTiOTwqeXRqr3e5/fVqO3qGTWPjFE0UU31qs6HWKUasNvWDR7OoPOf7AeEVMG0YGBcaZXKaGVkCiqKt9u/Y9QjsioHXPPcJK6KZ1RuDZMuK+cbO4JZyo96/EhkCoOk2kUV5VCqMlBmyMIuSGdcV8dmKpbytM6Tp/uhD/Vx550TuMvKO/pPv3wWZutrl8pdj8Of/6fECvvW4/rtW7call2YeE39UXFSEkLqrR7upb5qz+fNVynr2E9nt/LWi2T8OgWbvR5VerjWbWLm28UB6xN/9VnSioEqFop4ig1cs0qtRGOx6pq0bvU6vnTTbQC8tHEQ9nozToqAi6nFcRWmMpVaL5pDIz5BPF4G+mRKa29qYvHSawG4/wfXs0p54XYDK1T9AeA+xVDPfPkgexFXrxhfZmGT0JB9ByA8Sx37xMPMW3kZAJ/+r+vJX/2nADz4Su3C5FH8FWoTmo6Fj3z8LylHxKNweMdmxjdlHkmRpDHjZInDu3jJfFaslCCl7TGTprgIcc4p+6sMbKl8kFBYHnMoZjJvuahn4s2DlNTEFIpCe3szjWDqGXDIuzlHIRBNJiHKgydMjyY2TkfsowDCYao2Blh5YspDJp2eTjSm1LNOmIgl4+JIgUC9l9PvID2AFm/CaIFhYsEJFsFBSUzNwSy1PZWx9s5z5pNOyxjp6e2kOSLRdC9evoiEWgiaEhEiVYOxMKaKxhwPRUhERIWX6d2I7YXhdoqUbZH67VCSex9+FIDr/+2r1Rb83pkzWDJPrhuqCW44Nm4APuT77vmc3Y8WEZpCSUqDenH3lsQS9b17/UEdp6LnCdd3zvFkZauHmQ3W27AZdnsxHmLoaBV+g6xWOEW5Ge7O07iRECAvuD8d/diemwdUVuJIOkte3cGQ6RBSyXhD4QThZGzU40fCtovVDBe4ZcIlmdhs18VVaj7XDVOy5Rm6loMdkRl7ydXLufPOOmGap8J//kxCKWzcvJEtW6Rfgxmw1fBdtGAmS5eKAFgMl+jNibHpGe+C7b5oEKnka6XTAxkol8Yhte4fgP3+EAj1luURIRPOlY3K333hCvoz0vfe/j5OViq8PfTDLFF3fvizX6KtXd6/RDhCzJVR29YcJ67mp6hl090lKuOf3H0vv7jl/9Vpw3vQs6HfGCYABKJlgAABAgQIECDAhHBcmalG5Fgb2NQp3PXqjVtIp4WyXbtqezV9lI0OurdgGjjKU8RBs0j9m/ZSVhR4H9Ck/vHg3T+hWwVZWbliPh+5VsLurfm7x2p2mZ6UeZhaD5+xsGv4VRg+2txDFX7nHMXJWy7ZgrTTioR56WWdT2XfHjn/I/e9SqEgd+UzV1xMVKUSWLxgKkXlhWNaZtXAvUQZKyy7xVhrnIQKfOSEig2rMp0ov3VOHGMpMg8A/Sq7Q6ls4BZkpEfCJhGVSDFbPlC9b8XcARrZnPvHu1e9H81CTTzboJeN8ilABf3CRXxtYQYuV35QHAzMWJxv3/y31SNf+OFjAERCGS5SgWZzmTwR9ba4Zf3WRGMxsgVRcXd2byERF9rELmXJ54Rn682b3PjLZxmJx7bto3ObWOU3GNGqiosBz2XhM8CLvt4qbTNDT++gj9eqrSz0MB+NkzlEY7Hzxot0g/WcEsxSlYcdmKZUPE4zJFUaJjsEu/0TmzeQzgMaipFazx1kdBiK2ssObqSgZhWrECOs3AutcAQr1PiyY2JiK5VTOBzCI32z2QKu6+m0HMrK0SMSj1BUp0+01jeQPvMCaFkuNy6+cBkXqsm+lCsylJeFwinbWJZSKboOsZDcuI45u2qYqWSTmKS8/097uO9/lMV3CRKx8bgt+Y34R2aD9av51Ig8NcrHrhM/0sWtUbIDMvnMa22iTXnH9qc+xWWXiAamuaWdYlH6FQuVsRQz1bNlI2tWiwr9njtvaaCdcTTvanGsxAcv5pfDsZjT3jgcV2HqivfCXSoRVo76kcgHgK/dqj1LYoqcH0ITnU1oer37oPYpKCL5uECSIodVpTRaDZPp7aakFrsf3fBVenboc3oTpoE+53hTTP3Oe/6c2FwJgJcd3MRzP//HIx9wyixOXyB0cnZTNzf915cBSDYlyChhyjHBVt5/eTvPli0iSq5ZtYFkUlQgm9Z1s/qXsuxbwONqWP75e2CZUu2VyjZW3Eu2XMZ0PJe/MlGzMZGx0sfoGUd/i3G3SlprmRWiIRk1S5cXsdIyCeczUC7KjbOLEhdvLHgTyzCvVwJlvwLb8n2qcAWEcdTq9YM7vl/3DF+99VaipvjeR22HtMq/5bg2RZW82rZtOntk5e7p1yEiMvv0e+z3JXvh1/dx/rvfX/0+XiHKQwHx1gP4FHCtKlfQGuoc9dVyLlqhMZ4saxPFdGBJg3XbmyGjHuFwJyxSB5pJqmvzE70wVbkRug4cVkL/qRfDrmMbcB7Qgn5mYydFPPf6dkKmqHPdqIUzDi+wXNElpISvaDiMrZ5GtlAkl1eefZa2mUqF0pSVF7Rl5fUewScvt7dPoVSWua9ICcuWm2hSAiVAFUtFTNfzmnaJhqQv6eYzAB01uGzJzZ291IX/UaO4DGFzPEofF001hKn6iE71hY49ZFMVptIWlywQtV0uX8QsS/tT8RTLVkhwZ2vlImIqLku5mGOwS2wWv/Pggzx9n2c92Kj4791E29fOEOOjGUaHt5ycMQO2HzOX5OOPQM0XIECAAAECBAgwARxXZqpjLiRVmIrdw0g2Ca8VSpeyGx0AsRlNtftjSkaoTa/h1fHn296yBVYslPKl74E+5d3W13WAgmK7nhjWHjvz0N5TfgnTn0+wEcSiFo/c/SP5sn3T2Adkh9mh1Jrs2stffuovAegdHGTHXvEJOvXkk2lpkz12qjnGunVyE+d2LCLeLKzW9d/6j7os2rcehx88LjumlhmgsvCQSEJLSvzUIvEQyUaNQgNWqi487637X9b71u9urdCitsTP++r+09shdjzpjlHh53y2vea/0RnnkFEBdA8e1DTG6TOmsWOfjsJ4/S2i8puDfnfyaMYnywiGd5QAjm8/Q8K1uqbLLDUJDI+XGvbBrzBZAHxalf1hP7PA3HNF0fDYS3pw+2NIRZEAnXAMY3mNghYkz18j2LIB2pUX6Wmt4JHOrYvAccSzNxutoLLDELZgv2Km6KAuazNReAFuezp7SUZaAYh2pIhExVzDcR3KTuN7+HwJLMWOlihSKikWyXSJqsCSZbuMo5KU5gtF8kVVPwwzlWP4Xl8fY5EOClkViNIq4ChTibATwlGLiYtZDaCczWUpWHKtnh6fn+YU6OoRi3675LN92APZ7HicJXxGFmfPhQXiNfu29jh9ygN8eCgDysj+tFIvRZXWpVCwaVIetMlYEk/BkErF6VXer1/4wvXsfN4XCGvc8LtWaNXqsTZAn8ysFBxnYSqXhZTySX5xGM0yng7T1Vp+YLueeP3T+2loW4IQ+jEOoc0ASuhHfcnVp2PnRIKKRaNku+UlKA7rTregA+m5SJRkkGjE/vCE47lJg92bYPtvGj+gAmzXVjlFNensKGSrv+3as4dde5Ri4hl96K93PkQqKi64R1pzvLO/sA9e8K/qPn/KP/mgiKvXEmAi8KcNHE09d9ezIry/2bF138tsffq1wRwfeOBBbrjhBgBuv+eXVdnoudfUHB+6tot9zuYtnRMSojz440pHgctVuRPwfLxsoGO2SmT3krbZKlEbHNWbA6Ywtup/KrUWMOPpygJgxbQxq0m78uBFGWhJgDdlDIWgp08Ubo5LdbeZSEL7FVKORGGXl0zwx76TnszYXrpno0PyO3oTuvs5SL9dyvE5TUTyamYuhzEdL2uDQ7HY+PY0U7SxSyKWhyNWNadpUyrOnNmSWtqNuLjKLjSXL5LLyrxfDjmU61xqzape2hbIPBtKDOGqgLJOKcSgiimTLxaq5yyVKtgRKT+11neiCAwMiXRquVH86B8YhzD1+xdBUs7/3jnNpMrywFrCNiUV9DmXimBnZFUqZC2d6NN0SUalHLFchrpkoz20YYDP/ZckoT+444XG21IXHpVRRpsG+Gy4AgCBmi9AgAABAgQIEGBCOK7M1IM/gxUqQFT3Vp+SYQeYM0Y7SrATHWjPRHs67UFvki47C9JzRHeYdWIsWiIxmLasfZhBRfPOPxv6Va6q1EFtAGv7zumgd5b+sHWNYMG8BWx9aRzMlA9/+LH/oEklZ2uJt3HPIzeOeczP7r//qK41Ep19gVx9vPACOgjkZMIsFb10cGCADsUKaI5n4vCI6p/d++AxOZ9D7d5ZaXz4KBKrDkRxUcr4E9UJJuJVNJFj5wDxBh3BWjs00x+OQ79iqTb2wz6vgyGqxML2PtiuwomRRVu6T/U1uhHNTRjxFAKIQPYV/a+ditwLLynS1CxjpOTmKBZE12jbJqF442GQB4eGiKogr7FwhGjUS3kSxjRVftZivhrsuFQqV+lIFzhQR52+5+kDPHqvmGAsX5mupr2xyzbZXEFd9zBeOLRIFCxP/+frKzEo2iowabE2GmF39xCN4qufXEFU6f3XbOzkzn+ROIW/OzeBqfpeNF2efUxScb3j3e/DUg+qb/3DZHpF1bhp4xa2bpsoPzwSs9CrZJnaaIyNq/kaYXQnO46rMNVzAD7Vqi78bvjGr6W8F9iv9KWz0J50YbRN015go+93T9iZ6as/NABbXpUp2eFFBs8TZ+hHt4K6LMUc5JRewj8cBnxlE60eSCGR2xvuY2cPbz3/j6WP8Qgx5bYVDlnK60TsBkKq1aVimVxRJoLudavoySu31R09I09dF5XKaIrm8Vl5PP3MYw3VC3Bs0Hh2sjcPhtWC29PdTXd395ErTwD3/OrXx+Q8UWo9fb1lYCGgcuFyF7Bpw3ZeLzS6gHhR9tuArNLLN41WWSGcgvkSlYLN3fDc19U/WtCamU50QtQwteEQ7lWfIbQw1Ygt3wgvwHoBY2/+7928932SSn7OvN8lbkkjinaZeKTx7WkiFiWujMGiEYt4m4jEsXCUnEq23N/XTy4nusl0+nRcJfhks3tHXeGev13MPp7/wW7efrVM8C3zYriuN18fqKpt7CJ09tfppUvV/itXrBWhM7nGA2Xk3DA9KvDm3RsHYb/k//vN07X1pk+RUZJoamHdxi4AHljTzUvPjJLv9OT3AfD2y1YSV/chHo2xXiUG3Q7i73sAAApPSURBVL6lSxJbAxx6pt4ZECMaby0KobeB41PzneiCFARqvgABAgQIECBAgAnhuDJTw8BG5c23ZDFcqPJH3XtQM00xarOre3FiikjwTVBGo6rsovNjdR/Su7l5wBq1g3oBnUWhZ7g2IL7HfJXQHI6BNhC+cAq0LG68j6lkrBoU9PkXbkdM5+Hct3RU8x1t39ZXvfIUDrLoPMk/uKStifX3C/92YFxJbOphkrtGnODwVMonceyCPR4vdPV0c+s9x06997rBAC/cT/iwftcjgGd7vQoovsHb5vegPfiSaBPfsZip57pgnvJYXr8J7f0wkmjz7CBMvOxAkijQ67ffQ3cF2vtmJFlxvvps0J75ETW/92d+wzwVQNMJQaHkNeivxjxHhDKWCvgZDyVwFXXmOg5OWcqxWJyoyleaSKQYHBQVW7k8zExFgu0F7SYeRXvlHIZnbxXWyfybvdXUNXZJjx3XhV310kIOwaYtchPDI1bSoddqjkfF1zf0ckAFC2Xz6Jz10ks+AsDlV11DNCGjY/aCJTy64RIA8kWbue3C3LUmwrQkVJ7MeJxUXKjKiGUxpPLF9mSLbOyTt+K/b/gaPH97nav63cCmoLlev/4mABxnYQrgq4q6vLkdll8o5XX3aDfqKLX5rryJZQgtBDWjKbVBaiNCe+fZ4qszDf3uWL7zWGjV3j5VD0RQa/PaE4Nm70sDiEUcCvk+3y9iGfbSi/VDDx4G2ua1AnDB0oX0rVUz0J4jZFub+Rb53Pvi6HXGjaNLdBzg6DDZBCg/brz9x2NXejOgAgUlMITQ84GL9gzuQCsx3kh4FjYD6HZ2jFLXw/QYdPVKec8QOpT0yPAlnrtzlNoYM36o3KX8Ej0RjsAZyulxe6POYUp6fakPbFvMCEIJSMXObvAEYBfz2EVZtMMhSCZVsvBIlJCl8spFolXPu0K+gFMU9ZNVnoZd8MXhUGPhnEum8PLtr5Wgn1kLJ6mB0dICRbUQDQygHxDoqbINDqpd+kELiSoPkIV940jQeKCnVy9E5VG8AKecz8prPglAU2tT1WSkOW0yb7YIU1ETLBXc2cTFVCOp7LqgAnsWbQfLFIEoGY0wr0Xu4Yc/8QluvbtVrvXQv47S0sPoFdn/RgWA4G4ECBAgQIAAAQJMCMedmfKwai00KX2en0j0ZULApjaenGdHGUEL8iOJRm9DEEZvyCLoOIEWenPmD4h/hu/8radCs2Ki45Z4yjSKbC6rY4AwnbGjXM5gk4ooOth3Pz25sTwkpsPe/Bh1RsLLQ3+kLHOTmSsJEOC1KKPnBxNtOuufM+YC3z2ejaqDPrTyJEbjO9xIDJ5+WH3ZQv2p5my0902W+pqZmWhV4DD1g6qeD2mPzpsF230B1M5UwT+3+SbrKcBhRa6fMRciqoOuC7lBv0vckZHJHkDFzqRkZykW5e4kEy7lshdh0ySk0hiVi2VKOWF3skMHObj+tefMlg6DioeFPx3kAOxXU3cuASrjDOEY7F+kuh4DlSUJ04KDJX1sle6MgzEOF/DTWlKUVF9KZiuHtno0ob7JH/j8tbQ3pdV9cHBcqT/kQFTpGJt8LsJh16zmQAxZpjQWwCnjKqN513Wr46G1uYn3XyCu9vc99DN0JsvRcGxSyZxIeMOEqcEMPFgnH7A/CKdfe3wKejIsoRueRM8P/gTFYbTAlUJPVjnf72m0Oi89E9JKuIunoJqnMg9DjXu5kkpHaVENappzMQWln45jETWlB24iQSwpZSc/xOCg+BmHks3MvaBV2rmxi/2767m5HmD8YcjHStUbIMCJB2sKRJQ2Z2T6WM8PaQHgBXl46bi17LXwlCcZGg/FsmcI6FJfRpuj/LvTEnpyfQtVg9RzF1FNIJzrhmHPPqgTDEn1RqUEz6xSv4+IRKtMRJnxO2Cp+BPhgs6HapswqCbzmAvlcbiy9vXrcrm8n2xO5krTOYRKXUooBLG4GERFozGGsmIvWrJ1H+mBWculjhU5zAz1+z5gmlpYmpunU1Bza8gCFXmBmGWAK5Jhvij3AmBaAk5Rhm2FGKj0fRQLYh7SKFZ2NFN2RELrCzs87Um/RhvnX3sNAIsWLaWobG5DIVPLxC7V6O+uGyLsCVBYmJZWbHtqUL8w7ThO9dhYOERzUrEG71gKz9QTpgz0WxTYTI1EoOYLECBAgAABAgSYAN4wZmp+C6ytI/zupT6PUkZYJa/ssat++t5P6/uVZSaamUqg2ai2k6G1VcrpFCinEewSDKnd0+CrEFMB6q4Zu1tkB+/HcwmJmGk2bxbXmoMjIvkZU04GYGFHC2GlFpzdMrua/mB/rreBqx07TBvN6jRAgEkKKwwhb6KooIM5HdJpp9LA51X5Wo5v6smT1WeEWhVkw0p8/+xtU+tD4k14UbTtQwhOmi/FtjgocpzV66HiMVu9ME2xKrGFsNuf0u3c+s04rCwE9j1NdeI9dS5EvYm2FyKK9IgByXGsOg4QCSs3PCvCUEZYp3IRMqrNoTC0tR5WZRNiciPiyQhnR5UJRcdhEk1y4bJzmLCaZ8NtkIqJWi0SDlPKyQiwygZ2SdionYOVWvsRdd9cB2JxiVEVjlTIKBddy4J942DfOpoSlIoyIoeyNlM/KEm9lnQ0c8lKsfqPYmFFpE7E1GrTcIiqoXnYdPHIKNOkaqRuWSaux15RxvXUpq6Nqw4IESKVkAf/B1ddxj3eSvrMzb6WmuhBN5LrnVzw+yVa6J74y+Pl3Y67MPVW9bn8wtMYyIuH209HOLr55rwqEugIxoNomj6BdiEuo8d8TU49Q144gERKIgcDtLZDyuPUHejrlGK2GwrqZStNgXDjAXtxihUs1fJwKUezOvaVERJi5bAEmevauqcaxOCp50cLnHbsMEPNuNGpIUIhNZzMELhvmFwdIMDrA58NielSlaDsYa35chFVH8BNwDdVeUS8xGOOGegQMHHdNErosBljIo+O+RJGu/+V0IahJlV3xamLYL5Sb5UysF5FQ69sgimq/uGCtgPa7cvpC+jJ1aB+pE7AULk/CxnIKHulcBbmquvOXQyxtfWPrYdiCeySCEq53D6GVciB6RE9p4fC4KoVsGCXKagdaam4u7ogxprBNsUYrJivOrdxIAPFkOgtI2HYo+7VzLYKjnfwRrRJ6duorraHBqBf3QgrBAdV2J+aFBoNwLUL5JU5SCJiccWFErhjYVuchKU8E0MmIVOr6iyltjNdsFQMB9N1UaZUOJZW7dllq2pfViq7ZFRuxKF8gZxa6MpumJwXzT0U4dTFot/d9cxqdNh3l9qsk8dGmPr/7dwxCoAwEABBbPz/j2MVCBaibKM4U8kRBKssgTj/iX1xf/32O6axzOfOdt7h1vn6vC9rnnzhd9MSAOAFtjFKDwIA/JuTKQCAQEwBAARiCgAgEFMAAIGYAgAIxBQAQCCmAAACMQUAEIgpAIBATAEABGIKACAQUwAAgZgCAAjEFABAIKYAAAIxBQAQiCkAgEBMAQAEYgoAIBBTAACBmAIACMQUAEAgpgAAggObwcqEyI8oegAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터 시각화\n",
    "pltsize = 1\n",
    "plt.figure(figsize = (10 * pltsize, pltsize))\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(1,10,i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(np.transpose(X_train[i],(1,2,0)))\n",
    "    plt.title('Class : ' + str(y_train[i].item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before np.transpose :  torch.Size([3, 32, 32])\n",
      "after np.transpose :  torch.Size([32, 32, 3])\n"
     ]
    }
   ],
   "source": [
    "print('before np.transpose : ', X_train[0].size())\n",
    "print('after np.transpose : ',np.transpose(X_train[i],(1,2,0)).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ResNet34 모델 불러오기\n",
    "\n",
    "- **pretrained = False로 설정**하여 모델의 구조만 불러오고 **모델 구조 내에 존재하는 파라미터는 랜덤으로 샘플링한 값을 이용**한다.\n",
    "- 불러온 resnet34 모델의 **Fully Connected Layer의 Input에 해당하는 노드 수**를 **num_ftrs**로 지정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "model = models.resnet34(pretrained = False)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 10)\n",
    "model = model.cuda() # model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Optimizer, Objective Function 설정\n",
    "\n",
    "- ResNet 모델을 DEVICE에 할당\n",
    "- 최적화 방식은 Adam\n",
    "- 최적화에 사용될 손실함수는 CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ResNet().to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 16, 16]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 16, 16]             128\n",
      "              ReLU-3           [-1, 64, 16, 16]               0\n",
      "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
      "            Conv2d-5             [-1, 64, 8, 8]          36,864\n",
      "       BatchNorm2d-6             [-1, 64, 8, 8]             128\n",
      "              ReLU-7             [-1, 64, 8, 8]               0\n",
      "            Conv2d-8             [-1, 64, 8, 8]          36,864\n",
      "       BatchNorm2d-9             [-1, 64, 8, 8]             128\n",
      "             ReLU-10             [-1, 64, 8, 8]               0\n",
      "       BasicBlock-11             [-1, 64, 8, 8]               0\n",
      "           Conv2d-12             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-13             [-1, 64, 8, 8]             128\n",
      "             ReLU-14             [-1, 64, 8, 8]               0\n",
      "           Conv2d-15             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-16             [-1, 64, 8, 8]             128\n",
      "             ReLU-17             [-1, 64, 8, 8]               0\n",
      "       BasicBlock-18             [-1, 64, 8, 8]               0\n",
      "           Conv2d-19             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-20             [-1, 64, 8, 8]             128\n",
      "             ReLU-21             [-1, 64, 8, 8]               0\n",
      "           Conv2d-22             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-23             [-1, 64, 8, 8]             128\n",
      "             ReLU-24             [-1, 64, 8, 8]               0\n",
      "       BasicBlock-25             [-1, 64, 8, 8]               0\n",
      "           Conv2d-26            [-1, 128, 4, 4]          73,728\n",
      "      BatchNorm2d-27            [-1, 128, 4, 4]             256\n",
      "             ReLU-28            [-1, 128, 4, 4]               0\n",
      "           Conv2d-29            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-30            [-1, 128, 4, 4]             256\n",
      "           Conv2d-31            [-1, 128, 4, 4]           8,192\n",
      "      BatchNorm2d-32            [-1, 128, 4, 4]             256\n",
      "             ReLU-33            [-1, 128, 4, 4]               0\n",
      "       BasicBlock-34            [-1, 128, 4, 4]               0\n",
      "           Conv2d-35            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-36            [-1, 128, 4, 4]             256\n",
      "             ReLU-37            [-1, 128, 4, 4]               0\n",
      "           Conv2d-38            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-39            [-1, 128, 4, 4]             256\n",
      "             ReLU-40            [-1, 128, 4, 4]               0\n",
      "       BasicBlock-41            [-1, 128, 4, 4]               0\n",
      "           Conv2d-42            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-43            [-1, 128, 4, 4]             256\n",
      "             ReLU-44            [-1, 128, 4, 4]               0\n",
      "           Conv2d-45            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-46            [-1, 128, 4, 4]             256\n",
      "             ReLU-47            [-1, 128, 4, 4]               0\n",
      "       BasicBlock-48            [-1, 128, 4, 4]               0\n",
      "           Conv2d-49            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-50            [-1, 128, 4, 4]             256\n",
      "             ReLU-51            [-1, 128, 4, 4]               0\n",
      "           Conv2d-52            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-53            [-1, 128, 4, 4]             256\n",
      "             ReLU-54            [-1, 128, 4, 4]               0\n",
      "       BasicBlock-55            [-1, 128, 4, 4]               0\n",
      "           Conv2d-56            [-1, 256, 2, 2]         294,912\n",
      "      BatchNorm2d-57            [-1, 256, 2, 2]             512\n",
      "             ReLU-58            [-1, 256, 2, 2]               0\n",
      "           Conv2d-59            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-60            [-1, 256, 2, 2]             512\n",
      "           Conv2d-61            [-1, 256, 2, 2]          32,768\n",
      "      BatchNorm2d-62            [-1, 256, 2, 2]             512\n",
      "             ReLU-63            [-1, 256, 2, 2]               0\n",
      "       BasicBlock-64            [-1, 256, 2, 2]               0\n",
      "           Conv2d-65            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-66            [-1, 256, 2, 2]             512\n",
      "             ReLU-67            [-1, 256, 2, 2]               0\n",
      "           Conv2d-68            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-69            [-1, 256, 2, 2]             512\n",
      "             ReLU-70            [-1, 256, 2, 2]               0\n",
      "       BasicBlock-71            [-1, 256, 2, 2]               0\n",
      "           Conv2d-72            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-73            [-1, 256, 2, 2]             512\n",
      "             ReLU-74            [-1, 256, 2, 2]               0\n",
      "           Conv2d-75            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-76            [-1, 256, 2, 2]             512\n",
      "             ReLU-77            [-1, 256, 2, 2]               0\n",
      "       BasicBlock-78            [-1, 256, 2, 2]               0\n",
      "           Conv2d-79            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-80            [-1, 256, 2, 2]             512\n",
      "             ReLU-81            [-1, 256, 2, 2]               0\n",
      "           Conv2d-82            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-83            [-1, 256, 2, 2]             512\n",
      "             ReLU-84            [-1, 256, 2, 2]               0\n",
      "       BasicBlock-85            [-1, 256, 2, 2]               0\n",
      "           Conv2d-86            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-87            [-1, 256, 2, 2]             512\n",
      "             ReLU-88            [-1, 256, 2, 2]               0\n",
      "           Conv2d-89            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-90            [-1, 256, 2, 2]             512\n",
      "             ReLU-91            [-1, 256, 2, 2]               0\n",
      "       BasicBlock-92            [-1, 256, 2, 2]               0\n",
      "           Conv2d-93            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-94            [-1, 256, 2, 2]             512\n",
      "             ReLU-95            [-1, 256, 2, 2]               0\n",
      "           Conv2d-96            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-97            [-1, 256, 2, 2]             512\n",
      "             ReLU-98            [-1, 256, 2, 2]               0\n",
      "       BasicBlock-99            [-1, 256, 2, 2]               0\n",
      "          Conv2d-100            [-1, 512, 1, 1]       1,179,648\n",
      "     BatchNorm2d-101            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-102            [-1, 512, 1, 1]               0\n",
      "          Conv2d-103            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-104            [-1, 512, 1, 1]           1,024\n",
      "          Conv2d-105            [-1, 512, 1, 1]         131,072\n",
      "     BatchNorm2d-106            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-107            [-1, 512, 1, 1]               0\n",
      "      BasicBlock-108            [-1, 512, 1, 1]               0\n",
      "          Conv2d-109            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-110            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-111            [-1, 512, 1, 1]               0\n",
      "          Conv2d-112            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-113            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-114            [-1, 512, 1, 1]               0\n",
      "      BasicBlock-115            [-1, 512, 1, 1]               0\n",
      "          Conv2d-116            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-117            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-118            [-1, 512, 1, 1]               0\n",
      "          Conv2d-119            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-120            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-121            [-1, 512, 1, 1]               0\n",
      "      BasicBlock-122            [-1, 512, 1, 1]               0\n",
      "AdaptiveAvgPool2d-123            [-1, 512, 1, 1]               0\n",
      "          Linear-124                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 21,289,802\n",
      "Trainable params: 21,289,802\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.97\n",
      "Params size (MB): 81.21\n",
      "Estimated Total Size (MB): 83.19\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# print(model)\n",
    "summary(model, input_size=(3, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 학습 데이터에 대한 모델 성능 확인하는 함수 정의\n",
    "\n",
    "1. CNN 모델을 학습 상태로 지정\n",
    "2. Mini-batch 단위로 저장된 데이터를 순서대로 이용하여 모델 학습\n",
    "3. 이미지 데이터와 레이블 데이터를 기존에 정의한 장비에 할당\n",
    "4. Optimizer 초기화\n",
    "5. output 계산 \n",
    "6. CrossEntropy를 통해 Loss 계산\n",
    "7. Backpropagation을 통한 파라미터 업데이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, log_interval):\n",
    "    model.train()\n",
    "    print(\"-------------------- Training..... --------------------\\n\")\n",
    "    for batch_idx, (image, label) in enumerate(train_loader):\n",
    "        image = image.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(image)\n",
    "        \n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step() # 파라미터 업데이트\n",
    "        \n",
    "        if batch_idx % log_interval == 0 :\n",
    "            print(\"Train Epoch: {} [{}/{}]\\tTrain Loss: {:.6f}\".format(Epoch,\n",
    "                                                                       len(image) * batch_idx,\n",
    "                                                                       len(train_loader.dataset),\n",
    "                                                                       loss.item()))\n",
    "    print(\"--------------------------------------------------------\\n\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 검증 데이터에 대한 모델 성능을 확인하는 함수 정의\n",
    "\n",
    "1. 모델을 평가 상태로 지정\n",
    "2. Gradient의 흐름을 억제하여 파라미터 값이 업데이트되는 현상 방지\n",
    "3. 이후 과정은 *7. 학습 데이터에 대한 모델 성능을 확인하는 함수 정의* 와 동일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for image, label in test_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            \n",
    "            output = model(image)\n",
    "            test_loss += criterion(output, label)\n",
    "            prediction = output.max(1, keepdim = True)[1] # 가장 큰 확률 값을 지니는 클래스의 인덱스만 추출\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
    "            \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    \n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 모델 학습 및 성능 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Training..... --------------------\n",
      "\n",
      "Train Epoch: 1 [0/50000]\tTrain Loss: 2.428457\n",
      "Train Epoch: 1 [6400/50000]\tTrain Loss: 1.391500\n",
      "Train Epoch: 1 [12800/50000]\tTrain Loss: 1.438986\n",
      "Train Epoch: 1 [19200/50000]\tTrain Loss: 1.948861\n",
      "Train Epoch: 1 [25600/50000]\tTrain Loss: 1.721593\n",
      "Train Epoch: 1 [32000/50000]\tTrain Loss: 1.351236\n",
      "Train Epoch: 1 [38400/50000]\tTrain Loss: 1.122242\n",
      "Train Epoch: 1 [44800/50000]\tTrain Loss: 1.038510\n",
      "--------------------------------------------------------\n",
      "\n",
      "[EPOCH: 1] Test Loss: 0.0384 \tTest Accracy: 57.23%\n",
      "\n",
      "-------------------- Training..... --------------------\n",
      "\n",
      "Train Epoch: 2 [0/50000]\tTrain Loss: 1.214507\n",
      "Train Epoch: 2 [6400/50000]\tTrain Loss: 1.061634\n",
      "Train Epoch: 2 [12800/50000]\tTrain Loss: 0.930815\n",
      "Train Epoch: 2 [19200/50000]\tTrain Loss: 1.459097\n",
      "Train Epoch: 2 [25600/50000]\tTrain Loss: 1.293411\n",
      "Train Epoch: 2 [32000/50000]\tTrain Loss: 1.369463\n",
      "Train Epoch: 2 [38400/50000]\tTrain Loss: 0.931824\n",
      "Train Epoch: 2 [44800/50000]\tTrain Loss: 0.867476\n",
      "--------------------------------------------------------\n",
      "\n",
      "[EPOCH: 2] Test Loss: 0.0299 \tTest Accracy: 66.79%\n",
      "\n",
      "-------------------- Training..... --------------------\n",
      "\n",
      "Train Epoch: 3 [0/50000]\tTrain Loss: 1.188758\n",
      "Train Epoch: 3 [6400/50000]\tTrain Loss: 0.888045\n",
      "Train Epoch: 3 [12800/50000]\tTrain Loss: 0.929246\n",
      "Train Epoch: 3 [19200/50000]\tTrain Loss: 1.238378\n",
      "Train Epoch: 3 [25600/50000]\tTrain Loss: 1.030678\n",
      "Train Epoch: 3 [32000/50000]\tTrain Loss: 1.144726\n",
      "Train Epoch: 3 [38400/50000]\tTrain Loss: 0.629131\n",
      "Train Epoch: 3 [44800/50000]\tTrain Loss: 0.672932\n",
      "--------------------------------------------------------\n",
      "\n",
      "[EPOCH: 3] Test Loss: 0.0272 \tTest Accracy: 70.10%\n",
      "\n",
      "-------------------- Training..... --------------------\n",
      "\n",
      "Train Epoch: 4 [0/50000]\tTrain Loss: 0.849074\n",
      "Train Epoch: 4 [6400/50000]\tTrain Loss: 0.945472\n",
      "Train Epoch: 4 [12800/50000]\tTrain Loss: 0.859358\n",
      "Train Epoch: 4 [19200/50000]\tTrain Loss: 1.021277\n",
      "Train Epoch: 4 [25600/50000]\tTrain Loss: 0.882932\n",
      "Train Epoch: 4 [32000/50000]\tTrain Loss: 0.982701\n",
      "Train Epoch: 4 [38400/50000]\tTrain Loss: 0.924779\n",
      "Train Epoch: 4 [44800/50000]\tTrain Loss: 0.695652\n",
      "--------------------------------------------------------\n",
      "\n",
      "[EPOCH: 4] Test Loss: 0.0242 \tTest Accracy: 73.31%\n",
      "\n",
      "-------------------- Training..... --------------------\n",
      "\n",
      "Train Epoch: 5 [0/50000]\tTrain Loss: 0.782907\n",
      "Train Epoch: 5 [6400/50000]\tTrain Loss: 0.748809\n",
      "Train Epoch: 5 [12800/50000]\tTrain Loss: 0.801871\n",
      "Train Epoch: 5 [19200/50000]\tTrain Loss: 0.806260\n",
      "Train Epoch: 5 [25600/50000]\tTrain Loss: 0.649286\n",
      "Train Epoch: 5 [32000/50000]\tTrain Loss: 0.791530\n",
      "Train Epoch: 5 [38400/50000]\tTrain Loss: 0.614990\n",
      "Train Epoch: 5 [44800/50000]\tTrain Loss: 0.614386\n",
      "--------------------------------------------------------\n",
      "\n",
      "[EPOCH: 5] Test Loss: 0.0230 \tTest Accracy: 74.95%\n",
      "\n",
      "-------------------- Training..... --------------------\n",
      "\n",
      "Train Epoch: 6 [0/50000]\tTrain Loss: 0.530886\n",
      "Train Epoch: 6 [6400/50000]\tTrain Loss: 0.776885\n",
      "Train Epoch: 6 [12800/50000]\tTrain Loss: 0.704265\n",
      "Train Epoch: 6 [19200/50000]\tTrain Loss: 0.796939\n",
      "Train Epoch: 6 [25600/50000]\tTrain Loss: 0.642196\n",
      "Train Epoch: 6 [32000/50000]\tTrain Loss: 0.694195\n",
      "Train Epoch: 6 [38400/50000]\tTrain Loss: 0.649070\n",
      "Train Epoch: 6 [44800/50000]\tTrain Loss: 0.614058\n",
      "--------------------------------------------------------\n",
      "\n",
      "[EPOCH: 6] Test Loss: 0.0217 \tTest Accracy: 76.65%\n",
      "\n",
      "-------------------- Training..... --------------------\n",
      "\n",
      "Train Epoch: 7 [0/50000]\tTrain Loss: 0.486031\n",
      "Train Epoch: 7 [6400/50000]\tTrain Loss: 0.609860\n",
      "Train Epoch: 7 [12800/50000]\tTrain Loss: 0.978063\n",
      "Train Epoch: 7 [19200/50000]\tTrain Loss: 0.966841\n",
      "Train Epoch: 7 [25600/50000]\tTrain Loss: 0.415717\n",
      "Train Epoch: 7 [32000/50000]\tTrain Loss: 0.687691\n",
      "Train Epoch: 7 [38400/50000]\tTrain Loss: 0.808419\n",
      "Train Epoch: 7 [44800/50000]\tTrain Loss: 0.935894\n",
      "--------------------------------------------------------\n",
      "\n",
      "[EPOCH: 7] Test Loss: 0.0215 \tTest Accracy: 76.86%\n",
      "\n",
      "-------------------- Training..... --------------------\n",
      "\n",
      "Train Epoch: 8 [0/50000]\tTrain Loss: 0.415191\n",
      "Train Epoch: 8 [6400/50000]\tTrain Loss: 0.752065\n",
      "Train Epoch: 8 [12800/50000]\tTrain Loss: 0.581814\n",
      "Train Epoch: 8 [19200/50000]\tTrain Loss: 0.890039\n",
      "Train Epoch: 8 [25600/50000]\tTrain Loss: 0.546886\n",
      "Train Epoch: 8 [32000/50000]\tTrain Loss: 0.435398\n",
      "Train Epoch: 8 [38400/50000]\tTrain Loss: 0.393468\n",
      "Train Epoch: 8 [44800/50000]\tTrain Loss: 0.675843\n",
      "--------------------------------------------------------\n",
      "\n",
      "[EPOCH: 8] Test Loss: 0.0219 \tTest Accracy: 76.95%\n",
      "\n",
      "-------------------- Training..... --------------------\n",
      "\n",
      "Train Epoch: 9 [0/50000]\tTrain Loss: 0.522204\n",
      "Train Epoch: 9 [6400/50000]\tTrain Loss: 0.650352\n",
      "Train Epoch: 9 [12800/50000]\tTrain Loss: 0.551951\n",
      "Train Epoch: 9 [19200/50000]\tTrain Loss: 0.932518\n",
      "Train Epoch: 9 [25600/50000]\tTrain Loss: 0.292254\n",
      "Train Epoch: 9 [32000/50000]\tTrain Loss: 0.774959\n",
      "Train Epoch: 9 [38400/50000]\tTrain Loss: 0.692497\n",
      "Train Epoch: 9 [44800/50000]\tTrain Loss: 0.398191\n",
      "--------------------------------------------------------\n",
      "\n",
      "[EPOCH: 9] Test Loss: 0.0226 \tTest Accracy: 77.31%\n",
      "\n",
      "-------------------- Training..... --------------------\n",
      "\n",
      "Train Epoch: 10 [0/50000]\tTrain Loss: 0.392066\n",
      "Train Epoch: 10 [6400/50000]\tTrain Loss: 0.730534\n",
      "Train Epoch: 10 [12800/50000]\tTrain Loss: 0.697340\n",
      "Train Epoch: 10 [19200/50000]\tTrain Loss: 0.767751\n",
      "Train Epoch: 10 [25600/50000]\tTrain Loss: 0.219243\n",
      "Train Epoch: 10 [32000/50000]\tTrain Loss: 0.439057\n",
      "Train Epoch: 10 [38400/50000]\tTrain Loss: 0.398558\n",
      "Train Epoch: 10 [44800/50000]\tTrain Loss: 0.398353\n",
      "--------------------------------------------------------\n",
      "\n",
      "[EPOCH: 10] Test Loss: 0.0224 \tTest Accracy: 77.69%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for Epoch in range(1, EPOCHS + 1):\n",
    "    train(model, train_loader, optimizer, log_interval = 200)\n",
    "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
    "    print(\"[EPOCH: {}] Test Loss: {:.4f} \\tTest Accracy: {:.2f}%\\n\".format(Epoch,\n",
    "                                                                            test_loss,\n",
    "                                                                            test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ➕ ImageNet 데이터로 학습된 ResNet34 모델을 불러온 후 Fine-tuning 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Training..... --------------------\n",
      "\n",
      "Train Epoch: 1 [0/50000]\tTrain Loss: 2.635197\n",
      "Train Epoch: 1 [6400/50000]\tTrain Loss: 1.143671\n",
      "Train Epoch: 1 [12800/50000]\tTrain Loss: 1.392290\n",
      "Train Epoch: 1 [19200/50000]\tTrain Loss: 1.272022\n",
      "Train Epoch: 1 [25600/50000]\tTrain Loss: 0.897255\n",
      "Train Epoch: 1 [32000/50000]\tTrain Loss: 0.925618\n",
      "Train Epoch: 1 [38400/50000]\tTrain Loss: 1.009339\n",
      "Train Epoch: 1 [44800/50000]\tTrain Loss: 1.001643\n",
      "--------------------------------------------------------\n",
      "\n",
      "[EPOCH: 1] Test Loss: 0.0299 \tTest Accracy: 68.79%\n",
      "\n",
      "-------------------- Training..... --------------------\n",
      "\n",
      "Train Epoch: 2 [0/50000]\tTrain Loss: 0.911223\n",
      "Train Epoch: 2 [6400/50000]\tTrain Loss: 0.833055\n",
      "Train Epoch: 2 [12800/50000]\tTrain Loss: 0.964783\n",
      "Train Epoch: 2 [19200/50000]\tTrain Loss: 1.147692\n",
      "Train Epoch: 2 [25600/50000]\tTrain Loss: 0.772254\n",
      "Train Epoch: 2 [32000/50000]\tTrain Loss: 0.814888\n",
      "Train Epoch: 2 [38400/50000]\tTrain Loss: 0.677064\n",
      "Train Epoch: 2 [44800/50000]\tTrain Loss: 0.723863\n",
      "--------------------------------------------------------\n",
      "\n",
      "[EPOCH: 2] Test Loss: 0.0213 \tTest Accracy: 76.80%\n",
      "\n",
      "-------------------- Training..... --------------------\n",
      "\n",
      "Train Epoch: 3 [0/50000]\tTrain Loss: 0.544014\n",
      "Train Epoch: 3 [6400/50000]\tTrain Loss: 0.668266\n",
      "Train Epoch: 3 [12800/50000]\tTrain Loss: 0.757027\n",
      "Train Epoch: 3 [19200/50000]\tTrain Loss: 1.041057\n",
      "Train Epoch: 3 [25600/50000]\tTrain Loss: 0.487406\n",
      "Train Epoch: 3 [32000/50000]\tTrain Loss: 0.705838\n",
      "Train Epoch: 3 [38400/50000]\tTrain Loss: 0.572880\n",
      "Train Epoch: 3 [44800/50000]\tTrain Loss: 0.764267\n",
      "--------------------------------------------------------\n",
      "\n",
      "[EPOCH: 3] Test Loss: 0.0240 \tTest Accracy: 77.45%\n",
      "\n",
      "-------------------- Training..... --------------------\n",
      "\n",
      "Train Epoch: 4 [0/50000]\tTrain Loss: 0.514704\n",
      "Train Epoch: 4 [6400/50000]\tTrain Loss: 0.644543\n",
      "Train Epoch: 4 [12800/50000]\tTrain Loss: 0.565533\n",
      "Train Epoch: 4 [19200/50000]\tTrain Loss: 0.951555\n",
      "Train Epoch: 4 [25600/50000]\tTrain Loss: 0.650872\n",
      "Train Epoch: 4 [32000/50000]\tTrain Loss: 0.523728\n",
      "Train Epoch: 4 [38400/50000]\tTrain Loss: 0.505806\n",
      "Train Epoch: 4 [44800/50000]\tTrain Loss: 0.520366\n",
      "--------------------------------------------------------\n",
      "\n",
      "[EPOCH: 4] Test Loss: 0.0221 \tTest Accracy: 76.82%\n",
      "\n",
      "-------------------- Training..... --------------------\n",
      "\n",
      "Train Epoch: 5 [0/50000]\tTrain Loss: 0.334323\n",
      "Train Epoch: 5 [6400/50000]\tTrain Loss: 0.540911\n",
      "Train Epoch: 5 [12800/50000]\tTrain Loss: 0.496008\n",
      "Train Epoch: 5 [19200/50000]\tTrain Loss: 1.156226\n",
      "Train Epoch: 5 [25600/50000]\tTrain Loss: 0.283167\n",
      "Train Epoch: 5 [32000/50000]\tTrain Loss: 0.563902\n",
      "Train Epoch: 5 [38400/50000]\tTrain Loss: 0.444764\n",
      "Train Epoch: 5 [44800/50000]\tTrain Loss: 0.506787\n",
      "--------------------------------------------------------\n",
      "\n",
      "[EPOCH: 5] Test Loss: 0.0754 \tTest Accracy: 71.47%\n",
      "\n",
      "-------------------- Training..... --------------------\n",
      "\n",
      "Train Epoch: 6 [0/50000]\tTrain Loss: 0.905120\n",
      "Train Epoch: 6 [6400/50000]\tTrain Loss: 0.603639\n",
      "Train Epoch: 6 [12800/50000]\tTrain Loss: 0.527953\n",
      "Train Epoch: 6 [19200/50000]\tTrain Loss: 0.769889\n",
      "Train Epoch: 6 [25600/50000]\tTrain Loss: 0.227152\n",
      "Train Epoch: 6 [32000/50000]\tTrain Loss: 0.487570\n",
      "Train Epoch: 6 [38400/50000]\tTrain Loss: 0.432704\n",
      "Train Epoch: 6 [44800/50000]\tTrain Loss: 0.311201\n",
      "--------------------------------------------------------\n",
      "\n",
      "[EPOCH: 6] Test Loss: 0.0195 \tTest Accracy: 79.57%\n",
      "\n",
      "-------------------- Training..... --------------------\n",
      "\n",
      "Train Epoch: 7 [0/50000]\tTrain Loss: 0.437583\n",
      "Train Epoch: 7 [6400/50000]\tTrain Loss: 0.917276\n",
      "Train Epoch: 7 [12800/50000]\tTrain Loss: 0.413771\n",
      "Train Epoch: 7 [19200/50000]\tTrain Loss: 0.771922\n",
      "Train Epoch: 7 [25600/50000]\tTrain Loss: 0.255004\n",
      "Train Epoch: 7 [32000/50000]\tTrain Loss: 0.491826\n",
      "Train Epoch: 7 [38400/50000]\tTrain Loss: 0.217567\n",
      "Train Epoch: 7 [44800/50000]\tTrain Loss: 0.510248\n",
      "--------------------------------------------------------\n",
      "\n",
      "[EPOCH: 7] Test Loss: 0.0199 \tTest Accracy: 79.50%\n",
      "\n",
      "-------------------- Training..... --------------------\n",
      "\n",
      "Train Epoch: 8 [0/50000]\tTrain Loss: 0.254174\n",
      "Train Epoch: 8 [6400/50000]\tTrain Loss: 0.684539\n",
      "Train Epoch: 8 [12800/50000]\tTrain Loss: 0.534110\n",
      "Train Epoch: 8 [19200/50000]\tTrain Loss: 0.618980\n",
      "Train Epoch: 8 [25600/50000]\tTrain Loss: 0.263421\n",
      "Train Epoch: 8 [32000/50000]\tTrain Loss: 0.314102\n",
      "Train Epoch: 8 [38400/50000]\tTrain Loss: 0.328459\n",
      "Train Epoch: 8 [44800/50000]\tTrain Loss: 0.424909\n",
      "--------------------------------------------------------\n",
      "\n",
      "[EPOCH: 8] Test Loss: 0.1575 \tTest Accracy: 67.92%\n",
      "\n",
      "-------------------- Training..... --------------------\n",
      "\n",
      "Train Epoch: 9 [0/50000]\tTrain Loss: 0.438290\n",
      "Train Epoch: 9 [6400/50000]\tTrain Loss: 0.437455\n",
      "Train Epoch: 9 [12800/50000]\tTrain Loss: 0.361794\n",
      "Train Epoch: 9 [19200/50000]\tTrain Loss: 0.671862\n",
      "Train Epoch: 9 [25600/50000]\tTrain Loss: 0.291312\n",
      "Train Epoch: 9 [32000/50000]\tTrain Loss: 0.326104\n",
      "Train Epoch: 9 [38400/50000]\tTrain Loss: 0.266788\n",
      "Train Epoch: 9 [44800/50000]\tTrain Loss: 0.277856\n",
      "--------------------------------------------------------\n",
      "\n",
      "[EPOCH: 9] Test Loss: 0.0250 \tTest Accracy: 79.91%\n",
      "\n",
      "-------------------- Training..... --------------------\n",
      "\n",
      "Train Epoch: 10 [0/50000]\tTrain Loss: 0.347552\n",
      "Train Epoch: 10 [6400/50000]\tTrain Loss: 0.407825\n",
      "Train Epoch: 10 [12800/50000]\tTrain Loss: 0.409414\n",
      "Train Epoch: 10 [19200/50000]\tTrain Loss: 0.624175\n",
      "Train Epoch: 10 [25600/50000]\tTrain Loss: 0.203393\n",
      "Train Epoch: 10 [32000/50000]\tTrain Loss: 0.233986\n",
      "Train Epoch: 10 [38400/50000]\tTrain Loss: 0.220796\n",
      "Train Epoch: 10 [44800/50000]\tTrain Loss: 0.300778\n",
      "--------------------------------------------------------\n",
      "\n",
      "[EPOCH: 10] Test Loss: 0.0385 \tTest Accracy: 79.53%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet34(pretrained = True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 10)\n",
    "model.to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "for Epoch in range(1, EPOCHS + 1):\n",
    "    train(model, train_loader, optimizer, log_interval = 200)\n",
    "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
    "    print(\"[EPOCH: {}] Test Loss: {:.4f} \\tTest Accracy: {:.2f}%\\n\".format(Epoch,\n",
    "                                                                            test_loss,\n",
    "                                                                            test_accuracy))    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
